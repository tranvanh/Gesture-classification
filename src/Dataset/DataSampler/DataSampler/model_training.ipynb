{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feature_computation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "caring-species"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
        "# dir_path = './' #local\n",
        "dir_path = './drive/MyDrive/BAKA/' #colab"
      ],
      "id": "caring-species",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "KstfPbJfzIAV",
        "outputId": "ff4f200b-07fc-4ddc-cbf7-a26d4598fd85"
      },
      "source": [
        "#uncomment in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', sep=' ', index_col=False )\n",
        "# test = np.genfromtxt(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', delimiter=' ',dtype='float64')\n",
        "df = pd.read_csv(dir_path + 'DataCollection' + '/' + '7' + '/' + '0.txt', header=None, sep=' ')\n",
        "# df.drop(df.index[100:])\n",
        "# filler = np.zeros((100-len(df), 31))\n",
        "# df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "# df\n",
        "if len(df.columns) > 31:\n",
        "  df = df.drop(columns=[31])\n",
        "df\n",
        "# sp_df = np.array_split(df, 2)\n",
        "# sp_df[0]"
      ],
      "id": "KstfPbJfzIAV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170.415</td>\n",
              "      <td>171.583</td>\n",
              "      <td>170.530</td>\n",
              "      <td>171.003</td>\n",
              "      <td>174.445</td>\n",
              "      <td>154.652</td>\n",
              "      <td>163.519</td>\n",
              "      <td>166.115</td>\n",
              "      <td>165.641</td>\n",
              "      <td>162.487</td>\n",
              "      <td>1.253290</td>\n",
              "      <td>194.882</td>\n",
              "      <td>14.9770</td>\n",
              "      <td>28.96000</td>\n",
              "      <td>189.262</td>\n",
              "      <td>-35.603500</td>\n",
              "      <td>45.53200</td>\n",
              "      <td>185.628</td>\n",
              "      <td>-45.093400</td>\n",
              "      <td>61.10950</td>\n",
              "      <td>180.397</td>\n",
              "      <td>-34.183900</td>\n",
              "      <td>73.7031</td>\n",
              "      <td>181.117</td>\n",
              "      <td>-8.99203</td>\n",
              "      <td>48.142200</td>\n",
              "      <td>217.883</td>\n",
              "      <td>49.5742</td>\n",
              "      <td>3.75821</td>\n",
              "      <td>2.104970</td>\n",
              "      <td>4.13247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>169.329</td>\n",
              "      <td>172.484</td>\n",
              "      <td>170.150</td>\n",
              "      <td>171.597</td>\n",
              "      <td>174.496</td>\n",
              "      <td>152.873</td>\n",
              "      <td>165.641</td>\n",
              "      <td>165.928</td>\n",
              "      <td>166.465</td>\n",
              "      <td>163.127</td>\n",
              "      <td>-8.616610</td>\n",
              "      <td>191.839</td>\n",
              "      <td>15.2395</td>\n",
              "      <td>17.57970</td>\n",
              "      <td>188.431</td>\n",
              "      <td>-38.200900</td>\n",
              "      <td>33.65670</td>\n",
              "      <td>182.574</td>\n",
              "      <td>-46.765500</td>\n",
              "      <td>50.02620</td>\n",
              "      <td>176.931</td>\n",
              "      <td>-35.898400</td>\n",
              "      <td>62.9153</td>\n",
              "      <td>177.678</td>\n",
              "      <td>-10.54940</td>\n",
              "      <td>37.379600</td>\n",
              "      <td>215.672</td>\n",
              "      <td>48.2805</td>\n",
              "      <td>3.47132</td>\n",
              "      <td>1.757100</td>\n",
              "      <td>3.07063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>167.655</td>\n",
              "      <td>173.037</td>\n",
              "      <td>169.813</td>\n",
              "      <td>171.482</td>\n",
              "      <td>173.459</td>\n",
              "      <td>150.460</td>\n",
              "      <td>166.703</td>\n",
              "      <td>165.740</td>\n",
              "      <td>166.740</td>\n",
              "      <td>163.775</td>\n",
              "      <td>-19.081500</td>\n",
              "      <td>189.688</td>\n",
              "      <td>14.7336</td>\n",
              "      <td>5.56185</td>\n",
              "      <td>187.971</td>\n",
              "      <td>-40.991500</td>\n",
              "      <td>21.53430</td>\n",
              "      <td>180.185</td>\n",
              "      <td>-49.011700</td>\n",
              "      <td>38.13220</td>\n",
              "      <td>174.031</td>\n",
              "      <td>-38.143400</td>\n",
              "      <td>51.8784</td>\n",
              "      <td>174.688</td>\n",
              "      <td>-12.96820</td>\n",
              "      <td>25.849700</td>\n",
              "      <td>213.251</td>\n",
              "      <td>46.7521</td>\n",
              "      <td>2.55655</td>\n",
              "      <td>1.690020</td>\n",
              "      <td>2.64563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>166.571</td>\n",
              "      <td>173.503</td>\n",
              "      <td>169.197</td>\n",
              "      <td>171.677</td>\n",
              "      <td>172.458</td>\n",
              "      <td>148.909</td>\n",
              "      <td>167.125</td>\n",
              "      <td>165.531</td>\n",
              "      <td>167.099</td>\n",
              "      <td>163.716</td>\n",
              "      <td>-31.304300</td>\n",
              "      <td>190.266</td>\n",
              "      <td>15.0975</td>\n",
              "      <td>-7.45626</td>\n",
              "      <td>187.463</td>\n",
              "      <td>-42.522700</td>\n",
              "      <td>8.86878</td>\n",
              "      <td>178.043</td>\n",
              "      <td>-49.996400</td>\n",
              "      <td>25.58150</td>\n",
              "      <td>171.274</td>\n",
              "      <td>-39.126900</td>\n",
              "      <td>39.5904</td>\n",
              "      <td>171.037</td>\n",
              "      <td>-13.77820</td>\n",
              "      <td>13.845000</td>\n",
              "      <td>211.619</td>\n",
              "      <td>45.9054</td>\n",
              "      <td>2.16560</td>\n",
              "      <td>1.736170</td>\n",
              "      <td>2.39077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>165.696</td>\n",
              "      <td>175.323</td>\n",
              "      <td>170.447</td>\n",
              "      <td>172.439</td>\n",
              "      <td>173.044</td>\n",
              "      <td>147.501</td>\n",
              "      <td>169.382</td>\n",
              "      <td>166.810</td>\n",
              "      <td>168.132</td>\n",
              "      <td>165.104</td>\n",
              "      <td>-44.488500</td>\n",
              "      <td>191.750</td>\n",
              "      <td>15.3027</td>\n",
              "      <td>-19.92800</td>\n",
              "      <td>188.088</td>\n",
              "      <td>-44.296900</td>\n",
              "      <td>-3.93108</td>\n",
              "      <td>176.573</td>\n",
              "      <td>-51.103000</td>\n",
              "      <td>12.17790</td>\n",
              "      <td>169.156</td>\n",
              "      <td>-40.123200</td>\n",
              "      <td>26.3311</td>\n",
              "      <td>168.231</td>\n",
              "      <td>-14.56410</td>\n",
              "      <td>0.791638</td>\n",
              "      <td>209.579</td>\n",
              "      <td>45.8894</td>\n",
              "      <td>1.54479</td>\n",
              "      <td>1.682020</td>\n",
              "      <td>2.90702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>161.179</td>\n",
              "      <td>149.029</td>\n",
              "      <td>152.195</td>\n",
              "      <td>151.016</td>\n",
              "      <td>150.205</td>\n",
              "      <td>152.997</td>\n",
              "      <td>126.959</td>\n",
              "      <td>124.467</td>\n",
              "      <td>127.138</td>\n",
              "      <td>123.439</td>\n",
              "      <td>-30.090100</td>\n",
              "      <td>184.622</td>\n",
              "      <td>38.2253</td>\n",
              "      <td>-37.25150</td>\n",
              "      <td>196.216</td>\n",
              "      <td>0.788915</td>\n",
              "      <td>-25.96480</td>\n",
              "      <td>177.172</td>\n",
              "      <td>0.577421</td>\n",
              "      <td>-6.30855</td>\n",
              "      <td>169.466</td>\n",
              "      <td>1.548870</td>\n",
              "      <td>16.9119</td>\n",
              "      <td>170.591</td>\n",
              "      <td>10.74000</td>\n",
              "      <td>20.691400</td>\n",
              "      <td>219.560</td>\n",
              "      <td>52.5405</td>\n",
              "      <td>2.51276</td>\n",
              "      <td>0.449101</td>\n",
              "      <td>10.67120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>160.792</td>\n",
              "      <td>151.716</td>\n",
              "      <td>152.281</td>\n",
              "      <td>150.662</td>\n",
              "      <td>149.034</td>\n",
              "      <td>151.989</td>\n",
              "      <td>126.807</td>\n",
              "      <td>125.764</td>\n",
              "      <td>127.363</td>\n",
              "      <td>122.859</td>\n",
              "      <td>-19.908700</td>\n",
              "      <td>181.773</td>\n",
              "      <td>35.9630</td>\n",
              "      <td>-26.55300</td>\n",
              "      <td>188.969</td>\n",
              "      <td>0.309116</td>\n",
              "      <td>-15.62690</td>\n",
              "      <td>172.253</td>\n",
              "      <td>-1.190490</td>\n",
              "      <td>4.36088</td>\n",
              "      <td>165.698</td>\n",
              "      <td>0.422513</td>\n",
              "      <td>26.8130</td>\n",
              "      <td>168.415</td>\n",
              "      <td>10.13660</td>\n",
              "      <td>29.739400</td>\n",
              "      <td>217.434</td>\n",
              "      <td>50.6622</td>\n",
              "      <td>3.39557</td>\n",
              "      <td>0.308685</td>\n",
              "      <td>8.73040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>160.418</td>\n",
              "      <td>150.423</td>\n",
              "      <td>151.525</td>\n",
              "      <td>148.881</td>\n",
              "      <td>146.811</td>\n",
              "      <td>151.084</td>\n",
              "      <td>123.746</td>\n",
              "      <td>125.563</td>\n",
              "      <td>125.645</td>\n",
              "      <td>121.057</td>\n",
              "      <td>-9.673830</td>\n",
              "      <td>180.636</td>\n",
              "      <td>35.3971</td>\n",
              "      <td>-14.54250</td>\n",
              "      <td>184.884</td>\n",
              "      <td>1.792140</td>\n",
              "      <td>-4.11838</td>\n",
              "      <td>169.524</td>\n",
              "      <td>-1.451800</td>\n",
              "      <td>16.21090</td>\n",
              "      <td>164.016</td>\n",
              "      <td>1.369290</td>\n",
              "      <td>37.9906</td>\n",
              "      <td>167.859</td>\n",
              "      <td>11.25630</td>\n",
              "      <td>39.445900</td>\n",
              "      <td>216.438</td>\n",
              "      <td>50.7116</td>\n",
              "      <td>4.15535</td>\n",
              "      <td>0.403556</td>\n",
              "      <td>7.08729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>160.405</td>\n",
              "      <td>148.238</td>\n",
              "      <td>151.163</td>\n",
              "      <td>147.639</td>\n",
              "      <td>144.736</td>\n",
              "      <td>150.975</td>\n",
              "      <td>120.556</td>\n",
              "      <td>124.997</td>\n",
              "      <td>123.932</td>\n",
              "      <td>119.012</td>\n",
              "      <td>0.594164</td>\n",
              "      <td>179.349</td>\n",
              "      <td>34.9790</td>\n",
              "      <td>-2.71361</td>\n",
              "      <td>183.277</td>\n",
              "      <td>3.301830</td>\n",
              "      <td>7.35355</td>\n",
              "      <td>168.698</td>\n",
              "      <td>-1.786510</td>\n",
              "      <td>27.97520</td>\n",
              "      <td>163.769</td>\n",
              "      <td>2.372690</td>\n",
              "      <td>49.2641</td>\n",
              "      <td>168.144</td>\n",
              "      <td>12.92220</td>\n",
              "      <td>49.179900</td>\n",
              "      <td>215.835</td>\n",
              "      <td>51.6498</td>\n",
              "      <td>4.51655</td>\n",
              "      <td>0.880348</td>\n",
              "      <td>5.78411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>160.564</td>\n",
              "      <td>146.276</td>\n",
              "      <td>149.128</td>\n",
              "      <td>145.866</td>\n",
              "      <td>144.428</td>\n",
              "      <td>151.505</td>\n",
              "      <td>118.473</td>\n",
              "      <td>123.934</td>\n",
              "      <td>122.046</td>\n",
              "      <td>117.167</td>\n",
              "      <td>9.941240</td>\n",
              "      <td>178.114</td>\n",
              "      <td>34.2215</td>\n",
              "      <td>8.80764</td>\n",
              "      <td>181.508</td>\n",
              "      <td>3.710370</td>\n",
              "      <td>19.79860</td>\n",
              "      <td>167.853</td>\n",
              "      <td>-2.419180</td>\n",
              "      <td>40.66870</td>\n",
              "      <td>163.733</td>\n",
              "      <td>2.781280</td>\n",
              "      <td>61.1570</td>\n",
              "      <td>168.660</td>\n",
              "      <td>14.18840</td>\n",
              "      <td>58.279200</td>\n",
              "      <td>215.528</td>\n",
              "      <td>52.2852</td>\n",
              "      <td>4.78537</td>\n",
              "      <td>1.117080</td>\n",
              "      <td>4.63972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0        1        2        3   ...       27       28        29        30\n",
              "0   170.415  171.583  170.530  171.003  ...  49.5742  3.75821  2.104970   4.13247\n",
              "1   169.329  172.484  170.150  171.597  ...  48.2805  3.47132  1.757100   3.07063\n",
              "2   167.655  173.037  169.813  171.482  ...  46.7521  2.55655  1.690020   2.64563\n",
              "3   166.571  173.503  169.197  171.677  ...  45.9054  2.16560  1.736170   2.39077\n",
              "4   165.696  175.323  170.447  172.439  ...  45.8894  1.54479  1.682020   2.90702\n",
              "..      ...      ...      ...      ...  ...      ...      ...       ...       ...\n",
              "95  161.179  149.029  152.195  151.016  ...  52.5405  2.51276  0.449101  10.67120\n",
              "96  160.792  151.716  152.281  150.662  ...  50.6622  3.39557  0.308685   8.73040\n",
              "97  160.418  150.423  151.525  148.881  ...  50.7116  4.15535  0.403556   7.08729\n",
              "98  160.405  148.238  151.163  147.639  ...  51.6498  4.51655  0.880348   5.78411\n",
              "99  160.564  146.276  149.128  145.866  ...  52.2852  4.78537  1.117080   4.63972\n",
              "\n",
              "[100 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "signal-friendly",
        "outputId": "df5185f7-2ae6-4efc-966d-9d4cd71605d1"
      },
      "source": [
        "files = os.listdir(dir_path + 'DataCollection')\n",
        "files"
      ],
      "id": "signal-friendly",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '2', '3', '4', '1', '5', '6', '7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "annoying-rotation",
        "outputId": "8875b52a-3487-4d47-f3da-e848be0d8c6e"
      },
      "source": [
        "x_train = [];\n",
        "y_train = [];\n",
        "\n",
        "x_test = [];\n",
        "y_test = [];\n",
        "for i in files:\n",
        "    samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
        "    num_tests = int(len(samples)/5);\n",
        "    shuffle(samples, random_state = 0)\n",
        "    for k in range(0, num_tests):\n",
        "#         df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_test.append(df.to_numpy())\n",
        "        y_test.append(int(i));\n",
        "    \n",
        "    for k in range(num_tests, len(samples)):\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # df = df.drop(df.index[100:])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_train.append(df.to_numpy())\n",
        "        y_train.append(int(i));\n",
        "    \n",
        "    print(len(samples), ' ', num_tests, ' ', len(samples)- num_tests)\n",
        "# print(len(x_train))\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train);\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n"
      ],
      "id": "annoying-rotation",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302   60   242\n",
            "512   102   410\n",
            "302   60   242\n",
            "410   82   328\n",
            "602   120   482\n",
            "422   84   338\n",
            "201   40   161\n",
            "201   40   161\n",
            "x_train.shape:  (2364, 100, 31)\n",
            "y_train.shiape:  (2364,)\n",
            "x_test.shape:  (588, 100, 31)\n",
            "y_test.shape:  (588,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_7kAXmt41Kf"
      },
      "source": [
        ""
      ],
      "id": "n_7kAXmt41Kf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orange-character",
        "outputId": "9e17c9f8-ac74-49fc-d043-00e268fa254b"
      },
      "source": [
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "\n"
      ],
      "id": "orange-character",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (2364, 100, 31)\n",
            "y_train.shiape:  (2364,)\n",
            "x_test.shape:  (588, 100, 31)\n",
            "y_test.shape:  (588,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-cheat"
      },
      "source": [
        "def scale_data(data, min_max_scaler):\n",
        "    for i in range(len(data)):\n",
        "        data[i] = min_max_scaler.transform(data[i])\n",
        "    return data"
      ],
      "id": "sensitive-cheat",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broke-sailing"
      },
      "source": [
        "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_train.shape\n",
        "x_train = np.reshape(x_train, newshape=(-1, num_features))\n",
        "x_train = min_max_scaler.fit_transform(x_train)\n",
        "x_train = np.reshape(x_train, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_test.shape\n",
        "x_test = np.reshape(x_test, newshape=(-1, num_features))\n",
        "x_test = min_max_scaler.transform(x_test)\n",
        "x_test = np.reshape(x_test, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_test, y_test = shuffle(x_test, y_test, random_state=0)\n"
      ],
      "id": "broke-sailing",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "discrete-kansas",
        "outputId": "6d0f9d86-1faa-407e-a699-d0f6ee03b10e"
      },
      "source": [
        "# x_train = np.delete(x_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "# y_train = np.delete(y_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "# print(y_train)\n",
        "# print(\"\\n\")\n",
        "# print(y_test)\n",
        "\n",
        "# y_train = y_train.astype('int')\n",
        "\n",
        "# print(y_train)\n"
      ],
      "id": "discrete-kansas",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (2364, 100, 31)\n",
            "y_train.shiape:  (2364,)\n",
            "x_test.shape:  (588, 100, 31)\n",
            "y_test.shape:  (588,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "senior-mystery",
        "outputId": "2cf5a4ca-1dd5-4693-9890-12b6cd598f96"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=100, input_shape=x_train.shape[1:], return_sequences=True,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True ,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True ,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "model.add(Dense(8, activation='softmax',dtype='float64'))\n",
        "model.summary()"
      ],
      "id": "senior-mystery",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 100)          52800     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 100)          400       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100, 100)          400       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100, 100)          400       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 808       \n",
            "=================================================================\n",
            "Total params: 296,408\n",
            "Trainable params: 295,608\n",
            "Non-trainable params: 800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "after-sperm",
        "outputId": "f02bfd9e-aba0-477c-d8d7-680c6fb2439d"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-5)\n",
        "\n",
        "checkpoint_filepath = dir_path + 'Checkpoints/'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "\n",
        "gestures = model.fit(x = x_train,\n",
        "            y = y_train,\n",
        "            epochs=50,\n",
        "            validation_split=0.1, #split 10% of the trainning set for the validation set,\n",
        "            batch_size=24,\n",
        "            callbacks=[model_checkpoint_callback],\n",
        "            shuffle=True\n",
        "         )"
      ],
      "id": "after-sperm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "89/89 [==============================] - 40s 64ms/step - loss: 1.3608 - accuracy: 0.5520 - val_loss: 1.9001 - val_accuracy: 0.5190\n",
            "Epoch 2/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.3158 - accuracy: 0.9189 - val_loss: 1.3572 - val_accuracy: 0.6709\n",
            "Epoch 3/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.2033 - accuracy: 0.9435 - val_loss: 0.7546 - val_accuracy: 0.7384\n",
            "Epoch 4/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1873 - accuracy: 0.9452 - val_loss: 0.4006 - val_accuracy: 0.8523\n",
            "Epoch 5/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1915 - accuracy: 0.9414 - val_loss: 0.2047 - val_accuracy: 0.9156\n",
            "Epoch 6/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1325 - accuracy: 0.9554 - val_loss: 0.0968 - val_accuracy: 0.9578\n",
            "Epoch 7/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1404 - accuracy: 0.9583 - val_loss: 0.4011 - val_accuracy: 0.8861\n",
            "Epoch 8/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1123 - accuracy: 0.9658 - val_loss: 0.2584 - val_accuracy: 0.9283\n",
            "Epoch 9/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1236 - accuracy: 0.9623 - val_loss: 0.0909 - val_accuracy: 0.9705\n",
            "Epoch 10/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0776 - accuracy: 0.9784 - val_loss: 0.0900 - val_accuracy: 0.9789\n",
            "Epoch 11/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0991 - accuracy: 0.9725 - val_loss: 0.1758 - val_accuracy: 0.9367\n",
            "Epoch 12/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0803 - accuracy: 0.9714 - val_loss: 0.0576 - val_accuracy: 0.9831\n",
            "Epoch 13/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 0.1405 - val_accuracy: 0.9536\n",
            "Epoch 14/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0817 - accuracy: 0.9732 - val_loss: 0.1496 - val_accuracy: 0.9494\n",
            "Epoch 15/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0819 - accuracy: 0.9762 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 16/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0620 - accuracy: 0.9844 - val_loss: 0.1126 - val_accuracy: 0.9662\n",
            "Epoch 17/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0555 - accuracy: 0.9834 - val_loss: 0.0725 - val_accuracy: 0.9747\n",
            "Epoch 18/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0503 - val_accuracy: 0.9873\n",
            "Epoch 19/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.0371 - val_accuracy: 0.9873\n",
            "Epoch 20/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.1132 - val_accuracy: 0.9620\n",
            "Epoch 21/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0314 - accuracy: 0.9939 - val_loss: 0.1154 - val_accuracy: 0.9662\n",
            "Epoch 22/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0401 - val_accuracy: 0.9873\n",
            "Epoch 23/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 0.0699 - val_accuracy: 0.9705\n",
            "Epoch 24/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0516 - accuracy: 0.9826 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
            "Epoch 25/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0328 - accuracy: 0.9904 - val_loss: 0.0514 - val_accuracy: 0.9873\n",
            "Epoch 26/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.0315 - val_accuracy: 0.9873\n",
            "Epoch 27/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0373 - accuracy: 0.9928 - val_loss: 0.5328 - val_accuracy: 0.8776\n",
            "Epoch 28/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.1059 - accuracy: 0.9656 - val_loss: 0.2633 - val_accuracy: 0.9156\n",
            "Epoch 29/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0492 - accuracy: 0.9883 - val_loss: 0.0996 - val_accuracy: 0.9662\n",
            "Epoch 30/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0403 - accuracy: 0.9904 - val_loss: 0.0545 - val_accuracy: 0.9873\n",
            "Epoch 31/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 1.2149 - val_accuracy: 0.7806\n",
            "Epoch 32/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 0.0841 - val_accuracy: 0.9747\n",
            "Epoch 33/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.0254 - val_accuracy: 0.9916\n",
            "Epoch 34/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.4238 - val_accuracy: 0.8861\n",
            "Epoch 35/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0265 - accuracy: 0.9940 - val_loss: 0.0487 - val_accuracy: 0.9831\n",
            "Epoch 36/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.0519 - val_accuracy: 0.9831\n",
            "Epoch 37/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0351 - val_accuracy: 0.9873\n",
            "Epoch 38/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0399 - accuracy: 0.9839 - val_loss: 0.0650 - val_accuracy: 0.9747\n",
            "Epoch 39/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.0585 - val_accuracy: 0.9873\n",
            "Epoch 40/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 41/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0326 - accuracy: 0.9925 - val_loss: 0.2002 - val_accuracy: 0.9494\n",
            "Epoch 42/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 0.0107 - val_accuracy: 0.9958\n",
            "Epoch 43/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.0585 - val_accuracy: 0.9873\n",
            "Epoch 44/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0495 - val_accuracy: 0.9873\n",
            "Epoch 45/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.1045 - val_accuracy: 0.9536\n",
            "Epoch 46/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 0.0375 - val_accuracy: 0.9873\n",
            "Epoch 47/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0271 - val_accuracy: 0.9873\n",
            "Epoch 48/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0501 - accuracy: 0.9885 - val_loss: 0.0591 - val_accuracy: 0.9831\n",
            "Epoch 49/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0117 - val_accuracy: 0.9958\n",
            "Epoch 50/50\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.0225 - val_accuracy: 0.9873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KikcQb9ZpuLB"
      },
      "source": [
        "# model.save(dir_path + 'Models/gestures.h5')"
      ],
      "id": "KikcQb9ZpuLB",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "integrated-optimization",
        "outputId": "888a0ec6-dd0a-4cfa-dc5d-9e4a54cb2086"
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=24)\n",
        "print(\"test loss, test acc:\", results)\n",
        "model.save(dir_path + 'Models/gestures_simplified_dynamic', save_format='tf')"
      ],
      "id": "integrated-optimization",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.0958 - accuracy: 0.9745\n",
            "test loss, test acc: [0.09583073854446411, 0.9744898080825806]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_simplified_dynamic/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_simplified_dynamic/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFsQ_tEXw8WX"
      },
      "source": [
        "# new_model = load_model(dir_path + 'Models/gestures.h5')\n",
        "# print(\"Evaluate on test data\")\n",
        "# results = new_model.evaluate(x_test, y_test, batch_size=80)\n",
        "# print(\"test loss, test acc:\", results)"
      ],
      "id": "hFsQ_tEXw8WX",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faWZ2lOQ09Dj",
        "outputId": "c0b9c776-3f65-4fbb-dab8-0e72ac259fac"
      },
      "source": [
        "min_max_scaler.data_max_"
      ],
      "id": "faWZ2lOQ09Dj",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([180.   , 179.999, 180.   , 179.996, 179.995, 179.999, 179.989,\n",
              "       180.   , 179.991, 179.986, 579.577, 719.193, 570.106, 549.272,\n",
              "       778.684, 578.49 , 533.127, 791.146, 551.114, 543.578, 783.643,\n",
              "       520.983, 550.029, 762.745, 508.462, 519.313, 723.459, 526.573,\n",
              "       173.127, 162.605, 164.575])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOWq0Fev1RI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7ba512-a18d-464f-ca55-49cd81c7faf6"
      },
      "source": [
        "model.input"
      ],
      "id": "NOWq0Fev1RI-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 100, 31) dtype=float64 (created by layer 'lstm_input')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIACF0-aQgh"
      },
      "source": [
        ""
      ],
      "id": "FhIACF0-aQgh",
      "execution_count": 15,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caring-species",
   "metadata": {
    "id": "caring-species"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "dir_path = './' #local\n",
    "# dir_path = './drive/MyDrive/' #colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "KstfPbJfzIAV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KstfPbJfzIAV",
    "outputId": "cf3af350-7815-4f46-a0f9-eaf953d33ea3"
   },
   "outputs": [],
   "source": [
    "#uncomment in colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', sep=' ', index_col=False )\n",
    "test = np.genfromtxt(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', delimiter=' ',dtype='float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "signal-friendly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "signal-friendly",
    "outputId": "f93b8411-a9e5-41e9-ea90-22c8f03d1f32"
   },
   "outputs": [],
   "source": [
    "files = os.listdir(dir_path + 'DataCollection')\n",
    "files\n",
    "x_train = [];\n",
    "y_train = [];\n",
    "\n",
    "x_test = [];\n",
    "y_test = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "impossible-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301   60\n",
      "256   51\n",
      "151   30\n",
      "205   41\n",
      "211   42\n",
      "151   30\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
    "    num_tests = int(len(samples)/5);\n",
    "    shuffle(samples, random_state = 0)\n",
    "    for k in range(0, num_tests):\n",
    "#         np.genfromtxt(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', delimiter=' ',dtype='float64')\n",
    "        df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
    "        x_test.append(df)\n",
    "        y_test.append(int(i)-1);\n",
    "    \n",
    "    for k in range(num_tests, len(samples)):\n",
    "        df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
    "        x_train.append(df)\n",
    "        y_train.append(int(i)-1);\n",
    "    \n",
    "    print(len(samples), ' ', num_tests)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train);\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "centered-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (1021, 200, 31)\n",
      "y_train.shiape:  (1021,)\n",
      "x_test.shape:  (254, 200, 31)\n",
      "y_test.shape:  (254,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shiape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "sensitive-cheat",
   "metadata": {
    "id": "sensitive-cheat"
   },
   "outputs": [],
   "source": [
    "def scale_data(data, min_max_scaler):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = min_max_scaler.transform(data[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "broke-sailing",
   "metadata": {
    "id": "broke-sailing"
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "num_instances, num_time_steps, num_features = x_train.shape\n",
    "x_train = np.reshape(x_train, newshape=(-1, num_features))\n",
    "x_train = min_max_scaler.fit_transform(x_train)\n",
    "x_train = np.reshape(x_train, newshape=(num_instances, num_time_steps, num_features))\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "\n",
    "num_instances, num_time_steps, num_features = x_test.shape\n",
    "x_test = np.reshape(x_test, newshape=(-1, num_features))\n",
    "x_test = min_max_scaler.transform(x_test)\n",
    "x_test = np.reshape(x_test, newshape=(num_instances, num_time_steps, num_features))\n",
    "\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "discrete-kansas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "discrete-kansas",
    "outputId": "94824b25-78c9-46a6-bb88-d460990ecc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (1021, 200, 31)\n",
      "y_train.shiape:  (1021,)\n",
      "x_test.shape:  (254, 200, 31)\n",
      "y_test.shape:  (254,)\n"
     ]
    }
   ],
   "source": [
    "# x_train = np.delete(x_train, [0,1,2,3,4,5,6,7,8], 0)\n",
    "# y_train = np.delete(y_train, [0,1,2,3,4,5,6,7,8], 0)\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shiape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n",
    "# print(y_train)\n",
    "# print(\"\\n\")\n",
    "# print(y_test)\n",
    "\n",
    "# print(x_train)\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "# print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "senior-mystery",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "senior-mystery",
    "outputId": "9a9208a9-c36e-4eb6-f966-fa9a2258a55c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 200)          185600    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 200)          320800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200, 200)          320800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                6030      \n",
      "=================================================================\n",
      "Total params: 1,154,030\n",
      "Trainable params: 1,154,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=200, input_shape=x_train.shape[1:], return_sequences=True,dtype='float64'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(200, return_sequences=True ,dtype='float64'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(200, return_sequences=True ,dtype='float64'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(200,dtype='float64'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "after-sperm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "after-sperm",
    "outputId": "ead8f3a1-b401-47c5-f1fb-d1ea973f7a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "10/10 [==============================] - 13s 215ms/step - loss: 3.3998 - accuracy: 0.0680 - val_loss: 3.3754 - val_accuracy: 0.0617\n",
      "Epoch 2/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 3.3652 - accuracy: 0.1136 - val_loss: 3.3294 - val_accuracy: 0.1111\n",
      "Epoch 3/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 3.3027 - accuracy: 0.1646 - val_loss: 3.1975 - val_accuracy: 0.0741\n",
      "Epoch 4/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 3.1503 - accuracy: 0.1715 - val_loss: 2.9221 - val_accuracy: 0.1235\n",
      "Epoch 5/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 2.9109 - accuracy: 0.1545 - val_loss: 2.6635 - val_accuracy: 0.1852\n",
      "Epoch 6/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 2.6489 - accuracy: 0.2534 - val_loss: 2.3839 - val_accuracy: 0.3210\n",
      "Epoch 7/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 2.3745 - accuracy: 0.3271 - val_loss: 2.0810 - val_accuracy: 0.3704\n",
      "Epoch 8/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 2.1226 - accuracy: 0.3965 - val_loss: 1.8113 - val_accuracy: 0.4198\n",
      "Epoch 9/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.8761 - accuracy: 0.4621 - val_loss: 1.6646 - val_accuracy: 0.4321\n",
      "Epoch 10/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.6824 - accuracy: 0.4727 - val_loss: 1.5807 - val_accuracy: 0.3951\n",
      "Epoch 11/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.5949 - accuracy: 0.5068 - val_loss: 1.3978 - val_accuracy: 0.5432\n",
      "Epoch 12/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.4547 - accuracy: 0.5535 - val_loss: 1.2846 - val_accuracy: 0.5679\n",
      "Epoch 13/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.3484 - accuracy: 0.6151 - val_loss: 1.2726 - val_accuracy: 0.5432\n",
      "Epoch 14/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.1993 - accuracy: 0.6406 - val_loss: 1.2143 - val_accuracy: 0.6049\n",
      "Epoch 15/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.2004 - accuracy: 0.6386 - val_loss: 1.1746 - val_accuracy: 0.6049\n",
      "Epoch 16/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.1748 - accuracy: 0.6636 - val_loss: 1.3895 - val_accuracy: 0.5185\n",
      "Epoch 17/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.1527 - accuracy: 0.5885 - val_loss: 1.3478 - val_accuracy: 0.5309\n",
      "Epoch 18/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.1536 - accuracy: 0.6353 - val_loss: 1.1732 - val_accuracy: 0.5802\n",
      "Epoch 19/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0266 - accuracy: 0.6572 - val_loss: 1.0022 - val_accuracy: 0.6543\n",
      "Epoch 20/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0328 - accuracy: 0.6878 - val_loss: 1.1910 - val_accuracy: 0.5926\n",
      "Epoch 21/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0998 - accuracy: 0.6560 - val_loss: 1.2356 - val_accuracy: 0.5802\n",
      "Epoch 22/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.0915 - accuracy: 0.6557 - val_loss: 1.1423 - val_accuracy: 0.6543\n",
      "Epoch 23/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.1026 - accuracy: 0.6301 - val_loss: 1.2021 - val_accuracy: 0.6049\n",
      "Epoch 24/800\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.0881 - accuracy: 0.6357 - val_loss: 1.2843 - val_accuracy: 0.5309\n",
      "Epoch 25/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0981 - accuracy: 0.6415 - val_loss: 1.0918 - val_accuracy: 0.6667\n",
      "Epoch 26/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0018 - accuracy: 0.6677 - val_loss: 1.0804 - val_accuracy: 0.6296\n",
      "Epoch 27/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.9607 - accuracy: 0.6726 - val_loss: 1.0231 - val_accuracy: 0.6543\n",
      "Epoch 28/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.8362 - accuracy: 0.7278 - val_loss: 0.9959 - val_accuracy: 0.6914\n",
      "Epoch 29/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.8869 - accuracy: 0.7417 - val_loss: 0.9434 - val_accuracy: 0.7284\n",
      "Epoch 30/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.9008 - accuracy: 0.7351 - val_loss: 0.9991 - val_accuracy: 0.6914\n",
      "Epoch 31/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.9565 - accuracy: 0.7063 - val_loss: 1.0211 - val_accuracy: 0.6914\n",
      "Epoch 32/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.8429 - accuracy: 0.7228 - val_loss: 0.9559 - val_accuracy: 0.6790\n",
      "Epoch 33/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7760 - accuracy: 0.7521 - val_loss: 1.0009 - val_accuracy: 0.7160\n",
      "Epoch 34/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.8953 - accuracy: 0.7137 - val_loss: 0.9862 - val_accuracy: 0.6543\n",
      "Epoch 35/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.9134 - accuracy: 0.7178 - val_loss: 1.0166 - val_accuracy: 0.6790\n",
      "Epoch 36/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.9207 - accuracy: 0.6904 - val_loss: 1.0145 - val_accuracy: 0.6420\n",
      "Epoch 37/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 1.0364 - accuracy: 0.6585 - val_loss: 1.1428 - val_accuracy: 0.5802\n",
      "Epoch 38/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 1.0641 - accuracy: 0.6409 - val_loss: 0.9480 - val_accuracy: 0.6420\n",
      "Epoch 39/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.9310 - accuracy: 0.6874 - val_loss: 1.0700 - val_accuracy: 0.6173\n",
      "Epoch 40/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.9528 - accuracy: 0.6876 - val_loss: 0.9542 - val_accuracy: 0.6543\n",
      "Epoch 41/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7886 - accuracy: 0.7763 - val_loss: 0.8722 - val_accuracy: 0.7284\n",
      "Epoch 42/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7080 - accuracy: 0.7887 - val_loss: 0.9229 - val_accuracy: 0.7160\n",
      "Epoch 43/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7106 - accuracy: 0.8018 - val_loss: 0.9014 - val_accuracy: 0.6790\n",
      "Epoch 44/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7224 - accuracy: 0.7805 - val_loss: 0.9470 - val_accuracy: 0.7160\n",
      "Epoch 45/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.8126 - accuracy: 0.7449 - val_loss: 0.9688 - val_accuracy: 0.6914\n",
      "Epoch 46/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7955 - accuracy: 0.7421 - val_loss: 0.9367 - val_accuracy: 0.6543\n",
      "Epoch 47/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.9351 - accuracy: 0.6889 - val_loss: 0.9339 - val_accuracy: 0.7531\n",
      "Epoch 48/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.8218 - accuracy: 0.7391 - val_loss: 1.0940 - val_accuracy: 0.6296\n",
      "Epoch 49/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7513 - accuracy: 0.7655 - val_loss: 1.0246 - val_accuracy: 0.6790\n",
      "Epoch 50/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.7399 - accuracy: 0.8047 - val_loss: 0.8759 - val_accuracy: 0.7037\n",
      "Epoch 51/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6525 - accuracy: 0.8059 - val_loss: 0.8594 - val_accuracy: 0.7160\n",
      "Epoch 52/800\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.7077 - accuracy: 0.7834 - val_loss: 0.7985 - val_accuracy: 0.7407\n",
      "Epoch 53/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6677 - accuracy: 0.7863 - val_loss: 0.8010 - val_accuracy: 0.7778\n",
      "Epoch 54/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6577 - accuracy: 0.8275 - val_loss: 0.8196 - val_accuracy: 0.7654\n",
      "Epoch 55/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6313 - accuracy: 0.8376 - val_loss: 0.8314 - val_accuracy: 0.7654\n",
      "Epoch 56/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6503 - accuracy: 0.8370 - val_loss: 1.0440 - val_accuracy: 0.6914\n",
      "Epoch 57/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6796 - accuracy: 0.8029 - val_loss: 0.7914 - val_accuracy: 0.7654\n",
      "Epoch 58/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.7079 - accuracy: 0.7939 - val_loss: 1.1752 - val_accuracy: 0.6420\n",
      "Epoch 59/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.8933 - accuracy: 0.7375 - val_loss: 0.9035 - val_accuracy: 0.7037\n",
      "Epoch 60/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.7290 - accuracy: 0.7970 - val_loss: 0.8931 - val_accuracy: 0.7160\n",
      "Epoch 61/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6944 - accuracy: 0.8039 - val_loss: 0.7940 - val_accuracy: 0.7160\n",
      "Epoch 62/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.7046 - accuracy: 0.7913 - val_loss: 1.0713 - val_accuracy: 0.6543\n",
      "Epoch 63/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.6902 - accuracy: 0.7711 - val_loss: 0.8419 - val_accuracy: 0.8025\n",
      "Epoch 64/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6475 - accuracy: 0.8133 - val_loss: 0.6678 - val_accuracy: 0.8025\n",
      "Epoch 65/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5514 - accuracy: 0.8412 - val_loss: 0.7338 - val_accuracy: 0.7654\n",
      "Epoch 66/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5543 - accuracy: 0.8475 - val_loss: 1.0528 - val_accuracy: 0.7037\n",
      "Epoch 67/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6945 - accuracy: 0.7838 - val_loss: 1.0376 - val_accuracy: 0.6173\n",
      "Epoch 68/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.8505 - accuracy: 0.7391 - val_loss: 0.7175 - val_accuracy: 0.8272\n",
      "Epoch 69/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6678 - accuracy: 0.8278 - val_loss: 0.9320 - val_accuracy: 0.6914\n",
      "Epoch 70/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6542 - accuracy: 0.8227 - val_loss: 0.7534 - val_accuracy: 0.7901\n",
      "Epoch 71/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6597 - accuracy: 0.8071 - val_loss: 0.8329 - val_accuracy: 0.7654\n",
      "Epoch 72/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5211 - accuracy: 0.8645 - val_loss: 0.6624 - val_accuracy: 0.8395\n",
      "Epoch 73/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5698 - accuracy: 0.8593 - val_loss: 0.7432 - val_accuracy: 0.7531\n",
      "Epoch 74/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5686 - accuracy: 0.8331 - val_loss: 0.6411 - val_accuracy: 0.8519\n",
      "Epoch 75/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5838 - accuracy: 0.8541 - val_loss: 0.9261 - val_accuracy: 0.7037\n",
      "Epoch 76/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5151 - accuracy: 0.8590 - val_loss: 0.7811 - val_accuracy: 0.7531\n",
      "Epoch 77/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4666 - accuracy: 0.8745 - val_loss: 0.6768 - val_accuracy: 0.8148\n",
      "Epoch 78/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5171 - accuracy: 0.8692 - val_loss: 0.8396 - val_accuracy: 0.7654\n",
      "Epoch 79/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.7359 - accuracy: 0.7696 - val_loss: 0.8517 - val_accuracy: 0.7407\n",
      "Epoch 80/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.6391 - accuracy: 0.8202 - val_loss: 0.9065 - val_accuracy: 0.7407\n",
      "Epoch 81/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.7261 - accuracy: 0.7786 - val_loss: 0.8606 - val_accuracy: 0.7407\n",
      "Epoch 82/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.7280 - accuracy: 0.7956 - val_loss: 0.8627 - val_accuracy: 0.7407\n",
      "Epoch 83/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.6773 - accuracy: 0.8050 - val_loss: 0.7411 - val_accuracy: 0.8025\n",
      "Epoch 84/800\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.5602 - accuracy: 0.8292 - val_loss: 0.6782 - val_accuracy: 0.8025\n",
      "Epoch 85/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5118 - accuracy: 0.8551 - val_loss: 0.7903 - val_accuracy: 0.8025\n",
      "Epoch 86/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5055 - accuracy: 0.8698 - val_loss: 0.8932 - val_accuracy: 0.7778\n",
      "Epoch 87/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.7789 - accuracy: 0.7700 - val_loss: 0.6326 - val_accuracy: 0.8519\n",
      "Epoch 88/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5825 - accuracy: 0.8258 - val_loss: 0.9154 - val_accuracy: 0.7654\n",
      "Epoch 89/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.6752 - accuracy: 0.8019 - val_loss: 0.7449 - val_accuracy: 0.7901\n",
      "Epoch 90/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5786 - accuracy: 0.8535 - val_loss: 0.6638 - val_accuracy: 0.8272\n",
      "Epoch 91/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5227 - accuracy: 0.8534 - val_loss: 0.7060 - val_accuracy: 0.8148\n",
      "Epoch 92/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4885 - accuracy: 0.8871 - val_loss: 0.7419 - val_accuracy: 0.7901\n",
      "Epoch 93/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4851 - accuracy: 0.8735 - val_loss: 0.6733 - val_accuracy: 0.8148\n",
      "Epoch 94/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5013 - accuracy: 0.8825 - val_loss: 0.7137 - val_accuracy: 0.8395\n",
      "Epoch 95/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5071 - accuracy: 0.8506 - val_loss: 0.7738 - val_accuracy: 0.7901\n",
      "Epoch 96/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5251 - accuracy: 0.8493 - val_loss: 0.6689 - val_accuracy: 0.8272\n",
      "Epoch 97/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4728 - accuracy: 0.8820 - val_loss: 0.7018 - val_accuracy: 0.8148\n",
      "Epoch 98/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3902 - accuracy: 0.9120 - val_loss: 0.6648 - val_accuracy: 0.8025\n",
      "Epoch 99/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4195 - accuracy: 0.8908 - val_loss: 0.7090 - val_accuracy: 0.8272\n",
      "Epoch 100/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3491 - accuracy: 0.9341 - val_loss: 0.6423 - val_accuracy: 0.8519\n",
      "Epoch 101/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3842 - accuracy: 0.8990 - val_loss: 0.6956 - val_accuracy: 0.8272\n",
      "Epoch 102/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.3784 - accuracy: 0.9016 - val_loss: 0.6907 - val_accuracy: 0.8519\n",
      "Epoch 103/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4285 - accuracy: 0.8797 - val_loss: 0.7349 - val_accuracy: 0.8272\n",
      "Epoch 104/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4454 - accuracy: 0.8734 - val_loss: 0.6516 - val_accuracy: 0.8272\n",
      "Epoch 105/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4327 - accuracy: 0.8804 - val_loss: 0.6022 - val_accuracy: 0.8395\n",
      "Epoch 106/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4592 - accuracy: 0.8930 - val_loss: 0.7342 - val_accuracy: 0.8272\n",
      "Epoch 107/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3908 - accuracy: 0.8980 - val_loss: 0.7388 - val_accuracy: 0.8519\n",
      "Epoch 108/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3617 - accuracy: 0.9157 - val_loss: 0.6978 - val_accuracy: 0.8642\n",
      "Epoch 109/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3587 - accuracy: 0.9156 - val_loss: 0.7659 - val_accuracy: 0.7901\n",
      "Epoch 110/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.4049 - accuracy: 0.8996 - val_loss: 0.6537 - val_accuracy: 0.8519\n",
      "Epoch 111/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3369 - accuracy: 0.9176 - val_loss: 0.6967 - val_accuracy: 0.8272\n",
      "Epoch 112/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3681 - accuracy: 0.9001 - val_loss: 0.7323 - val_accuracy: 0.8148\n",
      "Epoch 113/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5507 - accuracy: 0.8380 - val_loss: 0.8614 - val_accuracy: 0.7160\n",
      "Epoch 114/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.8462 - accuracy: 0.7286 - val_loss: 0.8688 - val_accuracy: 0.7284\n",
      "Epoch 115/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.6594 - accuracy: 0.7912 - val_loss: 0.8317 - val_accuracy: 0.7654\n",
      "Epoch 116/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6092 - accuracy: 0.8108 - val_loss: 0.7516 - val_accuracy: 0.8395\n",
      "Epoch 117/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5587 - accuracy: 0.8498 - val_loss: 0.7613 - val_accuracy: 0.7901\n",
      "Epoch 118/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4236 - accuracy: 0.8865 - val_loss: 0.7836 - val_accuracy: 0.7901\n",
      "Epoch 119/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4922 - accuracy: 0.8756 - val_loss: 0.8031 - val_accuracy: 0.8148\n",
      "Epoch 120/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3973 - accuracy: 0.8999 - val_loss: 0.6675 - val_accuracy: 0.8148\n",
      "Epoch 121/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4008 - accuracy: 0.8915 - val_loss: 0.7554 - val_accuracy: 0.8148\n",
      "Epoch 122/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3571 - accuracy: 0.9182 - val_loss: 0.7006 - val_accuracy: 0.8148\n",
      "Epoch 123/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.3149 - accuracy: 0.9181 - val_loss: 0.8291 - val_accuracy: 0.7901\n",
      "Epoch 124/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4750 - accuracy: 0.8907 - val_loss: 0.8993 - val_accuracy: 0.8025\n",
      "Epoch 125/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5062 - accuracy: 0.8649 - val_loss: 0.9175 - val_accuracy: 0.7778\n",
      "Epoch 126/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3958 - accuracy: 0.8970 - val_loss: 0.8241 - val_accuracy: 0.7778\n",
      "Epoch 127/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4589 - accuracy: 0.8570 - val_loss: 0.7426 - val_accuracy: 0.7654\n",
      "Epoch 128/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4105 - accuracy: 0.8799 - val_loss: 0.7362 - val_accuracy: 0.8272\n",
      "Epoch 129/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4268 - accuracy: 0.8899 - val_loss: 0.7225 - val_accuracy: 0.8148\n",
      "Epoch 130/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3197 - accuracy: 0.9155 - val_loss: 0.8051 - val_accuracy: 0.7901\n",
      "Epoch 131/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3589 - accuracy: 0.9060 - val_loss: 0.9940 - val_accuracy: 0.7531\n",
      "Epoch 132/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5755 - accuracy: 0.8436 - val_loss: 0.9498 - val_accuracy: 0.7284\n",
      "Epoch 133/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.6063 - accuracy: 0.8431 - val_loss: 0.9025 - val_accuracy: 0.7531\n",
      "Epoch 134/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4422 - accuracy: 0.8798 - val_loss: 0.7271 - val_accuracy: 0.7778\n",
      "Epoch 135/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4372 - accuracy: 0.8816 - val_loss: 0.7393 - val_accuracy: 0.8148\n",
      "Epoch 136/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4749 - accuracy: 0.8811 - val_loss: 0.8013 - val_accuracy: 0.7901\n",
      "Epoch 137/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4012 - accuracy: 0.8851 - val_loss: 0.8094 - val_accuracy: 0.8148\n",
      "Epoch 138/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3583 - accuracy: 0.9116 - val_loss: 0.6747 - val_accuracy: 0.8148\n",
      "Epoch 139/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3692 - accuracy: 0.9063 - val_loss: 0.7613 - val_accuracy: 0.7778\n",
      "Epoch 140/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3678 - accuracy: 0.8983 - val_loss: 0.8207 - val_accuracy: 0.7901\n",
      "Epoch 141/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3518 - accuracy: 0.9031 - val_loss: 0.6900 - val_accuracy: 0.8272\n",
      "Epoch 142/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3382 - accuracy: 0.9075 - val_loss: 0.8193 - val_accuracy: 0.8148\n",
      "Epoch 143/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3332 - accuracy: 0.9143 - val_loss: 0.7908 - val_accuracy: 0.8025\n",
      "Epoch 144/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4696 - accuracy: 0.8706 - val_loss: 0.8346 - val_accuracy: 0.8025\n",
      "Epoch 145/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4599 - accuracy: 0.8792 - val_loss: 0.7038 - val_accuracy: 0.7778\n",
      "Epoch 146/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4760 - accuracy: 0.8644 - val_loss: 0.7597 - val_accuracy: 0.8025\n",
      "Epoch 147/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4321 - accuracy: 0.8735 - val_loss: 0.7714 - val_accuracy: 0.7901\n",
      "Epoch 148/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4373 - accuracy: 0.8908 - val_loss: 0.7737 - val_accuracy: 0.7654\n",
      "Epoch 149/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3610 - accuracy: 0.9001 - val_loss: 0.7756 - val_accuracy: 0.7901\n",
      "Epoch 150/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3657 - accuracy: 0.8971 - val_loss: 0.5842 - val_accuracy: 0.8642\n",
      "Epoch 151/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3622 - accuracy: 0.9063 - val_loss: 0.7756 - val_accuracy: 0.7901\n",
      "Epoch 152/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5692 - accuracy: 0.8329 - val_loss: 0.9706 - val_accuracy: 0.7531\n",
      "Epoch 153/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.6276 - accuracy: 0.8274 - val_loss: 0.8685 - val_accuracy: 0.7901\n",
      "Epoch 154/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6458 - accuracy: 0.8275 - val_loss: 0.7619 - val_accuracy: 0.8025\n",
      "Epoch 155/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5442 - accuracy: 0.8350 - val_loss: 0.7304 - val_accuracy: 0.8519\n",
      "Epoch 156/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4200 - accuracy: 0.8821 - val_loss: 0.7447 - val_accuracy: 0.8025\n",
      "Epoch 157/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3404 - accuracy: 0.9240 - val_loss: 0.7231 - val_accuracy: 0.8272\n",
      "Epoch 158/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3386 - accuracy: 0.9163 - val_loss: 0.7328 - val_accuracy: 0.8395\n",
      "Epoch 159/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3336 - accuracy: 0.9074 - val_loss: 0.6125 - val_accuracy: 0.8519\n",
      "Epoch 160/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2908 - accuracy: 0.9366 - val_loss: 0.7720 - val_accuracy: 0.8395\n",
      "Epoch 161/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3087 - accuracy: 0.9249 - val_loss: 0.6521 - val_accuracy: 0.8519\n",
      "Epoch 162/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2912 - accuracy: 0.9244 - val_loss: 0.6925 - val_accuracy: 0.8519\n",
      "Epoch 163/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2665 - accuracy: 0.9339 - val_loss: 0.6208 - val_accuracy: 0.8765\n",
      "Epoch 164/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3317 - accuracy: 0.9148 - val_loss: 0.7633 - val_accuracy: 0.8148\n",
      "Epoch 165/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3296 - accuracy: 0.9066 - val_loss: 0.6835 - val_accuracy: 0.8272\n",
      "Epoch 166/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2749 - accuracy: 0.9206 - val_loss: 0.6957 - val_accuracy: 0.8272\n",
      "Epoch 167/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2805 - accuracy: 0.9271 - val_loss: 0.8482 - val_accuracy: 0.8025\n",
      "Epoch 168/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3407 - accuracy: 0.9003 - val_loss: 0.6702 - val_accuracy: 0.8395\n",
      "Epoch 169/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2780 - accuracy: 0.9250 - val_loss: 0.6747 - val_accuracy: 0.8642\n",
      "Epoch 170/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2523 - accuracy: 0.9374 - val_loss: 0.6026 - val_accuracy: 0.8519\n",
      "Epoch 171/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3175 - accuracy: 0.9095 - val_loss: 0.7121 - val_accuracy: 0.8395\n",
      "Epoch 172/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3084 - accuracy: 0.9142 - val_loss: 0.7360 - val_accuracy: 0.8272\n",
      "Epoch 173/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3433 - accuracy: 0.9132 - val_loss: 0.7726 - val_accuracy: 0.8272\n",
      "Epoch 174/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2940 - accuracy: 0.9203 - val_loss: 0.7186 - val_accuracy: 0.8148\n",
      "Epoch 175/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3957 - accuracy: 0.9012 - val_loss: 0.6707 - val_accuracy: 0.8642\n",
      "Epoch 176/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.3041 - accuracy: 0.9262 - val_loss: 0.7462 - val_accuracy: 0.8395\n",
      "Epoch 177/800\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.3513 - accuracy: 0.9053 - val_loss: 0.8600 - val_accuracy: 0.8148\n",
      "Epoch 178/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3973 - accuracy: 0.8849 - val_loss: 0.7277 - val_accuracy: 0.8395\n",
      "Epoch 179/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3644 - accuracy: 0.8998 - val_loss: 0.9372 - val_accuracy: 0.7778\n",
      "Epoch 180/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6641 - accuracy: 0.8141 - val_loss: 0.8579 - val_accuracy: 0.7901\n",
      "Epoch 181/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5817 - accuracy: 0.8265 - val_loss: 0.7615 - val_accuracy: 0.8148\n",
      "Epoch 182/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.4360 - accuracy: 0.8731 - val_loss: 0.6757 - val_accuracy: 0.8395\n",
      "Epoch 183/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3381 - accuracy: 0.9241 - val_loss: 0.6788 - val_accuracy: 0.8272\n",
      "Epoch 184/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3483 - accuracy: 0.9169 - val_loss: 0.6757 - val_accuracy: 0.8519\n",
      "Epoch 185/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3340 - accuracy: 0.9118 - val_loss: 0.6200 - val_accuracy: 0.8642\n",
      "Epoch 186/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2747 - accuracy: 0.9287 - val_loss: 0.6220 - val_accuracy: 0.8519\n",
      "Epoch 187/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2624 - accuracy: 0.9322 - val_loss: 0.7226 - val_accuracy: 0.8395\n",
      "Epoch 188/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2663 - accuracy: 0.9290 - val_loss: 0.6302 - val_accuracy: 0.8519\n",
      "Epoch 189/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2482 - accuracy: 0.9278 - val_loss: 0.6124 - val_accuracy: 0.8519\n",
      "Epoch 190/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2475 - accuracy: 0.9276 - val_loss: 0.5450 - val_accuracy: 0.8889\n",
      "Epoch 191/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2362 - accuracy: 0.9405 - val_loss: 0.6891 - val_accuracy: 0.8395\n",
      "Epoch 192/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2415 - accuracy: 0.9392 - val_loss: 0.6262 - val_accuracy: 0.8642\n",
      "Epoch 193/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2422 - accuracy: 0.9353 - val_loss: 0.6230 - val_accuracy: 0.8642\n",
      "Epoch 194/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2810 - accuracy: 0.9209 - val_loss: 0.7016 - val_accuracy: 0.8519\n",
      "Epoch 195/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2761 - accuracy: 0.9214 - val_loss: 0.6596 - val_accuracy: 0.8519\n",
      "Epoch 196/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3268 - accuracy: 0.9087 - val_loss: 0.6894 - val_accuracy: 0.8395\n",
      "Epoch 197/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2926 - accuracy: 0.9256 - val_loss: 0.6027 - val_accuracy: 0.8642\n",
      "Epoch 198/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3286 - accuracy: 0.9089 - val_loss: 0.8593 - val_accuracy: 0.8148\n",
      "Epoch 199/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2999 - accuracy: 0.9185 - val_loss: 0.6460 - val_accuracy: 0.8519\n",
      "Epoch 200/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2641 - accuracy: 0.9236 - val_loss: 0.6520 - val_accuracy: 0.8519\n",
      "Epoch 201/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2781 - accuracy: 0.9243 - val_loss: 0.7290 - val_accuracy: 0.8025\n",
      "Epoch 202/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2787 - accuracy: 0.9263 - val_loss: 0.5618 - val_accuracy: 0.8889\n",
      "Epoch 203/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2434 - accuracy: 0.9318 - val_loss: 0.6043 - val_accuracy: 0.8765\n",
      "Epoch 204/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3493 - accuracy: 0.8958 - val_loss: 0.9068 - val_accuracy: 0.8148\n",
      "Epoch 205/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4777 - accuracy: 0.8554 - val_loss: 0.7335 - val_accuracy: 0.8148\n",
      "Epoch 206/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3545 - accuracy: 0.8934 - val_loss: 0.8336 - val_accuracy: 0.7778\n",
      "Epoch 207/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3144 - accuracy: 0.9057 - val_loss: 0.7177 - val_accuracy: 0.8272\n",
      "Epoch 208/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2541 - accuracy: 0.9267 - val_loss: 0.6510 - val_accuracy: 0.8519\n",
      "Epoch 209/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2661 - accuracy: 0.9275 - val_loss: 0.6536 - val_accuracy: 0.8272\n",
      "Epoch 210/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2679 - accuracy: 0.9265 - val_loss: 0.6703 - val_accuracy: 0.8395\n",
      "Epoch 211/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2488 - accuracy: 0.9329 - val_loss: 0.6970 - val_accuracy: 0.8519\n",
      "Epoch 212/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2614 - accuracy: 0.9417 - val_loss: 0.6316 - val_accuracy: 0.8519\n",
      "Epoch 213/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2050 - accuracy: 0.9455 - val_loss: 0.6145 - val_accuracy: 0.8642\n",
      "Epoch 214/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1777 - accuracy: 0.9539 - val_loss: 0.7196 - val_accuracy: 0.8642\n",
      "Epoch 215/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2882 - accuracy: 0.9246 - val_loss: 0.7350 - val_accuracy: 0.8272\n",
      "Epoch 216/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2788 - accuracy: 0.9282 - val_loss: 0.7303 - val_accuracy: 0.8519\n",
      "Epoch 217/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2509 - accuracy: 0.9321 - val_loss: 0.8886 - val_accuracy: 0.8148\n",
      "Epoch 218/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3260 - accuracy: 0.9087 - val_loss: 0.6760 - val_accuracy: 0.8519\n",
      "Epoch 219/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3340 - accuracy: 0.9013 - val_loss: 0.6596 - val_accuracy: 0.8642\n",
      "Epoch 220/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2507 - accuracy: 0.9230 - val_loss: 0.7133 - val_accuracy: 0.8272\n",
      "Epoch 221/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2399 - accuracy: 0.9429 - val_loss: 0.5985 - val_accuracy: 0.8889\n",
      "Epoch 222/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2513 - accuracy: 0.9379 - val_loss: 0.8116 - val_accuracy: 0.8272\n",
      "Epoch 223/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3148 - accuracy: 0.9044 - val_loss: 0.7439 - val_accuracy: 0.8025\n",
      "Epoch 224/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2875 - accuracy: 0.9104 - val_loss: 0.6208 - val_accuracy: 0.8395\n",
      "Epoch 225/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2354 - accuracy: 0.9365 - val_loss: 0.7081 - val_accuracy: 0.8272\n",
      "Epoch 226/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2938 - accuracy: 0.9127 - val_loss: 0.6350 - val_accuracy: 0.8272\n",
      "Epoch 227/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2541 - accuracy: 0.9334 - val_loss: 0.6476 - val_accuracy: 0.8642\n",
      "Epoch 228/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2750 - accuracy: 0.9219 - val_loss: 0.8463 - val_accuracy: 0.7901\n",
      "Epoch 229/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2758 - accuracy: 0.9256 - val_loss: 0.7255 - val_accuracy: 0.8025\n",
      "Epoch 230/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2391 - accuracy: 0.9380 - val_loss: 0.6129 - val_accuracy: 0.8765\n",
      "Epoch 231/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2310 - accuracy: 0.9227 - val_loss: 0.5985 - val_accuracy: 0.8395\n",
      "Epoch 232/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2677 - accuracy: 0.9289 - val_loss: 0.6324 - val_accuracy: 0.8642\n",
      "Epoch 233/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2510 - accuracy: 0.9336 - val_loss: 0.7993 - val_accuracy: 0.7901\n",
      "Epoch 234/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2271 - accuracy: 0.9364 - val_loss: 0.6224 - val_accuracy: 0.8395\n",
      "Epoch 235/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2147 - accuracy: 0.9419 - val_loss: 0.6903 - val_accuracy: 0.8395\n",
      "Epoch 236/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1694 - accuracy: 0.9545 - val_loss: 0.6439 - val_accuracy: 0.8519\n",
      "Epoch 237/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1848 - accuracy: 0.9550 - val_loss: 0.6256 - val_accuracy: 0.8765\n",
      "Epoch 238/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1994 - accuracy: 0.9410 - val_loss: 0.6319 - val_accuracy: 0.8765\n",
      "Epoch 239/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2342 - accuracy: 0.9311 - val_loss: 0.6027 - val_accuracy: 0.8642\n",
      "Epoch 240/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1794 - accuracy: 0.9461 - val_loss: 0.6311 - val_accuracy: 0.8519\n",
      "Epoch 241/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1842 - accuracy: 0.9485 - val_loss: 0.6395 - val_accuracy: 0.8642\n",
      "Epoch 242/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1550 - accuracy: 0.9542 - val_loss: 0.6446 - val_accuracy: 0.8765\n",
      "Epoch 243/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1597 - accuracy: 0.9564 - val_loss: 0.6616 - val_accuracy: 0.8519\n",
      "Epoch 244/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2036 - accuracy: 0.9397 - val_loss: 0.5892 - val_accuracy: 0.8765\n",
      "Epoch 245/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2696 - accuracy: 0.9213 - val_loss: 0.6848 - val_accuracy: 0.8148\n",
      "Epoch 246/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2767 - accuracy: 0.9237 - val_loss: 0.5912 - val_accuracy: 0.8642\n",
      "Epoch 247/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2312 - accuracy: 0.9343 - val_loss: 0.5681 - val_accuracy: 0.8765\n",
      "Epoch 248/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1786 - accuracy: 0.9565 - val_loss: 0.6570 - val_accuracy: 0.8765\n",
      "Epoch 249/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1997 - accuracy: 0.9457 - val_loss: 0.6238 - val_accuracy: 0.8765\n",
      "Epoch 250/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1818 - accuracy: 0.9525 - val_loss: 0.6520 - val_accuracy: 0.8765\n",
      "Epoch 251/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1838 - accuracy: 0.9494 - val_loss: 0.6278 - val_accuracy: 0.8642\n",
      "Epoch 252/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1783 - accuracy: 0.9528 - val_loss: 0.7144 - val_accuracy: 0.8519\n",
      "Epoch 253/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1707 - accuracy: 0.9529 - val_loss: 0.5783 - val_accuracy: 0.8889\n",
      "Epoch 254/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3379 - accuracy: 0.9041 - val_loss: 0.6895 - val_accuracy: 0.8519\n",
      "Epoch 255/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2424 - accuracy: 0.9206 - val_loss: 0.7959 - val_accuracy: 0.8025\n",
      "Epoch 256/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2480 - accuracy: 0.9299 - val_loss: 1.0041 - val_accuracy: 0.7654\n",
      "Epoch 257/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2984 - accuracy: 0.9186 - val_loss: 0.8124 - val_accuracy: 0.8272\n",
      "Epoch 258/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2130 - accuracy: 0.9442 - val_loss: 0.7190 - val_accuracy: 0.8519\n",
      "Epoch 259/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1886 - accuracy: 0.9508 - val_loss: 0.7092 - val_accuracy: 0.8519\n",
      "Epoch 260/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2327 - accuracy: 0.9326 - val_loss: 0.6534 - val_accuracy: 0.8642\n",
      "Epoch 261/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2496 - accuracy: 0.9319 - val_loss: 0.6715 - val_accuracy: 0.9012\n",
      "Epoch 262/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2410 - accuracy: 0.9355 - val_loss: 1.0195 - val_accuracy: 0.7778\n",
      "Epoch 263/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4975 - accuracy: 0.8620 - val_loss: 0.6656 - val_accuracy: 0.8395\n",
      "Epoch 264/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3630 - accuracy: 0.8986 - val_loss: 0.7226 - val_accuracy: 0.8148\n",
      "Epoch 265/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2887 - accuracy: 0.9151 - val_loss: 0.7065 - val_accuracy: 0.8642\n",
      "Epoch 266/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2819 - accuracy: 0.9187 - val_loss: 0.7787 - val_accuracy: 0.8519\n",
      "Epoch 267/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2402 - accuracy: 0.9328 - val_loss: 0.6021 - val_accuracy: 0.8889\n",
      "Epoch 268/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2393 - accuracy: 0.9253 - val_loss: 0.6590 - val_accuracy: 0.8889\n",
      "Epoch 269/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2655 - accuracy: 0.9305 - val_loss: 0.5040 - val_accuracy: 0.9012\n",
      "Epoch 270/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2217 - accuracy: 0.9436 - val_loss: 0.6845 - val_accuracy: 0.8642\n",
      "Epoch 271/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1892 - accuracy: 0.9543 - val_loss: 0.7026 - val_accuracy: 0.8395\n",
      "Epoch 272/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2232 - accuracy: 0.9397 - val_loss: 0.7642 - val_accuracy: 0.8519\n",
      "Epoch 273/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2180 - accuracy: 0.9369 - val_loss: 0.6059 - val_accuracy: 0.8765\n",
      "Epoch 274/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2418 - accuracy: 0.9289 - val_loss: 0.7021 - val_accuracy: 0.8519\n",
      "Epoch 275/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2021 - accuracy: 0.9499 - val_loss: 0.6497 - val_accuracy: 0.8642\n",
      "Epoch 276/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1968 - accuracy: 0.9435 - val_loss: 0.6684 - val_accuracy: 0.8642\n",
      "Epoch 277/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1506 - accuracy: 0.9622 - val_loss: 0.6471 - val_accuracy: 0.8765\n",
      "Epoch 278/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1708 - accuracy: 0.9513 - val_loss: 0.6159 - val_accuracy: 0.8519\n",
      "Epoch 279/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1833 - accuracy: 0.9503 - val_loss: 0.7951 - val_accuracy: 0.8519\n",
      "Epoch 280/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2916 - accuracy: 0.9138 - val_loss: 0.6241 - val_accuracy: 0.8395\n",
      "Epoch 281/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1949 - accuracy: 0.9429 - val_loss: 0.6437 - val_accuracy: 0.8765\n",
      "Epoch 282/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1889 - accuracy: 0.9537 - val_loss: 0.7078 - val_accuracy: 0.8519\n",
      "Epoch 283/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1854 - accuracy: 0.9542 - val_loss: 0.5953 - val_accuracy: 0.8642\n",
      "Epoch 284/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2219 - accuracy: 0.9316 - val_loss: 0.7634 - val_accuracy: 0.8272\n",
      "Epoch 285/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1972 - accuracy: 0.9417 - val_loss: 0.6819 - val_accuracy: 0.8765\n",
      "Epoch 286/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1757 - accuracy: 0.9524 - val_loss: 0.6810 - val_accuracy: 0.8519\n",
      "Epoch 287/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1884 - accuracy: 0.9462 - val_loss: 0.7477 - val_accuracy: 0.8519\n",
      "Epoch 288/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3261 - accuracy: 0.9073 - val_loss: 0.6689 - val_accuracy: 0.8519\n",
      "Epoch 289/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2419 - accuracy: 0.9329 - val_loss: 0.8151 - val_accuracy: 0.8272\n",
      "Epoch 290/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2869 - accuracy: 0.9297 - val_loss: 0.6681 - val_accuracy: 0.8519\n",
      "Epoch 291/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4144 - accuracy: 0.9001 - val_loss: 0.7777 - val_accuracy: 0.8148\n",
      "Epoch 292/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2961 - accuracy: 0.9070 - val_loss: 0.7392 - val_accuracy: 0.8395\n",
      "Epoch 293/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2533 - accuracy: 0.9261 - val_loss: 0.6151 - val_accuracy: 0.8765\n",
      "Epoch 294/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2110 - accuracy: 0.9384 - val_loss: 0.7800 - val_accuracy: 0.8272\n",
      "Epoch 295/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2083 - accuracy: 0.9330 - val_loss: 0.6305 - val_accuracy: 0.8519\n",
      "Epoch 296/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1898 - accuracy: 0.9468 - val_loss: 0.6322 - val_accuracy: 0.8519\n",
      "Epoch 297/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1627 - accuracy: 0.9607 - val_loss: 0.6919 - val_accuracy: 0.8765\n",
      "Epoch 298/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2170 - accuracy: 0.9268 - val_loss: 0.6040 - val_accuracy: 0.9012\n",
      "Epoch 299/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1734 - accuracy: 0.9497 - val_loss: 0.6040 - val_accuracy: 0.8765\n",
      "Epoch 300/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1763 - accuracy: 0.9355 - val_loss: 0.6313 - val_accuracy: 0.8642\n",
      "Epoch 301/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1704 - accuracy: 0.9570 - val_loss: 0.6775 - val_accuracy: 0.8519\n",
      "Epoch 302/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1335 - accuracy: 0.9631 - val_loss: 0.5975 - val_accuracy: 0.8765\n",
      "Epoch 303/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1471 - accuracy: 0.9581 - val_loss: 0.6475 - val_accuracy: 0.8642\n",
      "Epoch 304/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1569 - accuracy: 0.9540 - val_loss: 0.8314 - val_accuracy: 0.8148\n",
      "Epoch 305/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2595 - accuracy: 0.9224 - val_loss: 0.6803 - val_accuracy: 0.8519\n",
      "Epoch 306/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2833 - accuracy: 0.9291 - val_loss: 0.6980 - val_accuracy: 0.8148\n",
      "Epoch 307/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2361 - accuracy: 0.9173 - val_loss: 0.7407 - val_accuracy: 0.8272\n",
      "Epoch 308/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2376 - accuracy: 0.9331 - val_loss: 0.5890 - val_accuracy: 0.8642\n",
      "Epoch 309/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2433 - accuracy: 0.9409 - val_loss: 0.7978 - val_accuracy: 0.8148\n",
      "Epoch 310/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2435 - accuracy: 0.9286 - val_loss: 0.6022 - val_accuracy: 0.8642\n",
      "Epoch 311/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2022 - accuracy: 0.9503 - val_loss: 0.5938 - val_accuracy: 0.8765\n",
      "Epoch 312/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2381 - accuracy: 0.9273 - val_loss: 0.6602 - val_accuracy: 0.8642\n",
      "Epoch 313/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1906 - accuracy: 0.9483 - val_loss: 0.5447 - val_accuracy: 0.8889\n",
      "Epoch 314/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.7272 - val_accuracy: 0.8519\n",
      "Epoch 315/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.6829 - accuracy: 0.8249 - val_loss: 1.0833 - val_accuracy: 0.7160\n",
      "Epoch 316/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.8534 - accuracy: 0.7572 - val_loss: 0.8752 - val_accuracy: 0.7037\n",
      "Epoch 317/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.5396 - accuracy: 0.8180 - val_loss: 0.6908 - val_accuracy: 0.8148\n",
      "Epoch 318/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.5321 - accuracy: 0.8607 - val_loss: 0.7354 - val_accuracy: 0.8148\n",
      "Epoch 319/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4907 - accuracy: 0.8622 - val_loss: 0.9144 - val_accuracy: 0.7901\n",
      "Epoch 320/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4672 - accuracy: 0.8755 - val_loss: 0.5777 - val_accuracy: 0.8519\n",
      "Epoch 321/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3512 - accuracy: 0.9046 - val_loss: 0.6664 - val_accuracy: 0.8519\n",
      "Epoch 322/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3038 - accuracy: 0.9286 - val_loss: 0.6208 - val_accuracy: 0.8272\n",
      "Epoch 323/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3184 - accuracy: 0.9091 - val_loss: 0.6223 - val_accuracy: 0.8395\n",
      "Epoch 324/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2543 - accuracy: 0.9367 - val_loss: 0.6224 - val_accuracy: 0.8519\n",
      "Epoch 325/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2647 - accuracy: 0.9238 - val_loss: 0.5537 - val_accuracy: 0.8765\n",
      "Epoch 326/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1921 - accuracy: 0.9516 - val_loss: 0.5459 - val_accuracy: 0.8889\n",
      "Epoch 327/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2481 - accuracy: 0.9368 - val_loss: 0.6670 - val_accuracy: 0.8642\n",
      "Epoch 328/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2309 - accuracy: 0.9402 - val_loss: 0.6659 - val_accuracy: 0.8642\n",
      "Epoch 329/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2163 - accuracy: 0.9353 - val_loss: 0.5633 - val_accuracy: 0.8642\n",
      "Epoch 330/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2455 - accuracy: 0.9298 - val_loss: 0.7491 - val_accuracy: 0.7901\n",
      "Epoch 331/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3147 - accuracy: 0.9142 - val_loss: 0.6253 - val_accuracy: 0.8765\n",
      "Epoch 332/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3231 - accuracy: 0.9107 - val_loss: 0.5830 - val_accuracy: 0.8889\n",
      "Epoch 333/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2308 - accuracy: 0.9394 - val_loss: 0.6434 - val_accuracy: 0.8519\n",
      "Epoch 334/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2297 - accuracy: 0.9341 - val_loss: 0.6963 - val_accuracy: 0.8519\n",
      "Epoch 335/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2219 - accuracy: 0.9326 - val_loss: 0.6480 - val_accuracy: 0.8272\n",
      "Epoch 336/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2222 - accuracy: 0.9406 - val_loss: 0.6788 - val_accuracy: 0.8519\n",
      "Epoch 337/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2568 - accuracy: 0.9215 - val_loss: 0.6940 - val_accuracy: 0.8519\n",
      "Epoch 338/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2102 - accuracy: 0.9335 - val_loss: 0.7174 - val_accuracy: 0.8395\n",
      "Epoch 339/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1858 - accuracy: 0.9555 - val_loss: 0.6666 - val_accuracy: 0.8642\n",
      "Epoch 340/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1692 - accuracy: 0.9529 - val_loss: 0.6672 - val_accuracy: 0.8519\n",
      "Epoch 341/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2365 - accuracy: 0.9241 - val_loss: 0.6787 - val_accuracy: 0.8765\n",
      "Epoch 342/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2250 - accuracy: 0.9337 - val_loss: 0.6578 - val_accuracy: 0.8272\n",
      "Epoch 343/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2218 - accuracy: 0.9287 - val_loss: 0.7367 - val_accuracy: 0.8148\n",
      "Epoch 344/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2111 - accuracy: 0.9409 - val_loss: 0.7504 - val_accuracy: 0.8148\n",
      "Epoch 345/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1895 - accuracy: 0.9484 - val_loss: 0.6782 - val_accuracy: 0.8395\n",
      "Epoch 346/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1816 - accuracy: 0.9442 - val_loss: 0.7642 - val_accuracy: 0.8395\n",
      "Epoch 347/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1767 - accuracy: 0.9496 - val_loss: 0.6504 - val_accuracy: 0.8642\n",
      "Epoch 348/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1512 - accuracy: 0.9572 - val_loss: 0.7394 - val_accuracy: 0.8395\n",
      "Epoch 349/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1888 - accuracy: 0.9430 - val_loss: 0.6643 - val_accuracy: 0.8519\n",
      "Epoch 350/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1782 - accuracy: 0.9567 - val_loss: 0.6573 - val_accuracy: 0.8642\n",
      "Epoch 351/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1559 - accuracy: 0.9576 - val_loss: 0.7110 - val_accuracy: 0.8395\n",
      "Epoch 352/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1517 - accuracy: 0.9579 - val_loss: 0.6580 - val_accuracy: 0.8395\n",
      "Epoch 353/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1415 - accuracy: 0.9590 - val_loss: 0.6660 - val_accuracy: 0.8642\n",
      "Epoch 354/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1893 - accuracy: 0.9474 - val_loss: 0.6345 - val_accuracy: 0.8642\n",
      "Epoch 355/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1334 - accuracy: 0.9594 - val_loss: 0.6486 - val_accuracy: 0.8519\n",
      "Epoch 356/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1445 - accuracy: 0.9591 - val_loss: 0.6897 - val_accuracy: 0.8642\n",
      "Epoch 357/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 0.6790 - val_accuracy: 0.8642\n",
      "Epoch 358/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1222 - accuracy: 0.9683 - val_loss: 0.6914 - val_accuracy: 0.8519\n",
      "Epoch 359/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1153 - accuracy: 0.9701 - val_loss: 0.6717 - val_accuracy: 0.8395\n",
      "Epoch 360/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1492 - accuracy: 0.9519 - val_loss: 0.6865 - val_accuracy: 0.8395\n",
      "Epoch 361/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1544 - accuracy: 0.9607 - val_loss: 0.6124 - val_accuracy: 0.8642\n",
      "Epoch 362/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1470 - accuracy: 0.9649 - val_loss: 0.6646 - val_accuracy: 0.8642\n",
      "Epoch 363/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1383 - accuracy: 0.9615 - val_loss: 0.6229 - val_accuracy: 0.8519\n",
      "Epoch 364/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.1989 - accuracy: 0.9448 - val_loss: 0.6899 - val_accuracy: 0.8642\n",
      "Epoch 365/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1352 - accuracy: 0.9596 - val_loss: 0.5907 - val_accuracy: 0.8642\n",
      "Epoch 366/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1644 - accuracy: 0.9512 - val_loss: 0.6829 - val_accuracy: 0.8395\n",
      "Epoch 367/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1606 - accuracy: 0.9567 - val_loss: 0.7651 - val_accuracy: 0.8395\n",
      "Epoch 368/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1439 - accuracy: 0.9606 - val_loss: 0.6661 - val_accuracy: 0.8519\n",
      "Epoch 369/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1593 - accuracy: 0.9550 - val_loss: 0.6249 - val_accuracy: 0.8765\n",
      "Epoch 370/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1457 - accuracy: 0.9606 - val_loss: 0.5275 - val_accuracy: 0.8889\n",
      "Epoch 371/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1687 - accuracy: 0.9469 - val_loss: 0.6720 - val_accuracy: 0.8272\n",
      "Epoch 372/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1726 - accuracy: 0.9520 - val_loss: 0.5890 - val_accuracy: 0.8889\n",
      "Epoch 373/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2958 - accuracy: 0.9172 - val_loss: 2.5103 - val_accuracy: 0.5432\n",
      "Epoch 374/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 2.0421 - accuracy: 0.5495 - val_loss: 2.0138 - val_accuracy: 0.5926\n",
      "Epoch 375/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 1.4568 - accuracy: 0.6420 - val_loss: 1.5374 - val_accuracy: 0.6667\n",
      "Epoch 376/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 1.0335 - accuracy: 0.7309 - val_loss: 1.3881 - val_accuracy: 0.6420\n",
      "Epoch 377/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.8353 - accuracy: 0.7779 - val_loss: 1.1079 - val_accuracy: 0.7284\n",
      "Epoch 378/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.6157 - accuracy: 0.8333 - val_loss: 0.9749 - val_accuracy: 0.7531\n",
      "Epoch 379/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.5902 - accuracy: 0.8331 - val_loss: 0.9378 - val_accuracy: 0.7778\n",
      "Epoch 380/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4490 - accuracy: 0.8600 - val_loss: 0.8869 - val_accuracy: 0.7654\n",
      "Epoch 381/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.7241 - accuracy: 0.7905 - val_loss: 0.8066 - val_accuracy: 0.8395\n",
      "Epoch 382/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.6447 - accuracy: 0.8142 - val_loss: 1.3603 - val_accuracy: 0.6543\n",
      "Epoch 383/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 1.1910 - accuracy: 0.6669 - val_loss: 1.1432 - val_accuracy: 0.7037\n",
      "Epoch 384/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.9146 - accuracy: 0.7699 - val_loss: 1.0194 - val_accuracy: 0.7284\n",
      "Epoch 385/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.7249 - accuracy: 0.8219 - val_loss: 0.8926 - val_accuracy: 0.7284\n",
      "Epoch 386/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6353 - accuracy: 0.8268 - val_loss: 0.8295 - val_accuracy: 0.7654\n",
      "Epoch 387/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.6158 - accuracy: 0.8276 - val_loss: 0.7517 - val_accuracy: 0.8025\n",
      "Epoch 388/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.5223 - accuracy: 0.8698 - val_loss: 0.7997 - val_accuracy: 0.7654\n",
      "Epoch 389/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4828 - accuracy: 0.8707 - val_loss: 0.7299 - val_accuracy: 0.8025\n",
      "Epoch 390/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.3905 - accuracy: 0.8936 - val_loss: 0.7169 - val_accuracy: 0.8148\n",
      "Epoch 391/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4219 - accuracy: 0.8824 - val_loss: 0.6095 - val_accuracy: 0.8519\n",
      "Epoch 392/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3640 - accuracy: 0.9050 - val_loss: 0.6106 - val_accuracy: 0.8642\n",
      "Epoch 393/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3024 - accuracy: 0.9231 - val_loss: 0.6246 - val_accuracy: 0.8519\n",
      "Epoch 394/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3102 - accuracy: 0.9199 - val_loss: 0.6911 - val_accuracy: 0.8148\n",
      "Epoch 395/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3259 - accuracy: 0.9083 - val_loss: 0.6359 - val_accuracy: 0.8272\n",
      "Epoch 396/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2925 - accuracy: 0.9347 - val_loss: 0.6958 - val_accuracy: 0.8395\n",
      "Epoch 397/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3387 - accuracy: 0.9203 - val_loss: 0.6018 - val_accuracy: 0.8765\n",
      "Epoch 398/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2952 - accuracy: 0.9188 - val_loss: 0.5355 - val_accuracy: 0.8889\n",
      "Epoch 399/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3188 - accuracy: 0.9131 - val_loss: 0.5581 - val_accuracy: 0.8765\n",
      "Epoch 400/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2899 - accuracy: 0.9320 - val_loss: 0.6390 - val_accuracy: 0.8642\n",
      "Epoch 401/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2659 - accuracy: 0.9334 - val_loss: 0.5909 - val_accuracy: 0.8765\n",
      "Epoch 402/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2429 - accuracy: 0.9433 - val_loss: 0.5257 - val_accuracy: 0.8765\n",
      "Epoch 403/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2625 - accuracy: 0.9385 - val_loss: 0.7255 - val_accuracy: 0.8519\n",
      "Epoch 404/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2763 - accuracy: 0.9291 - val_loss: 0.7222 - val_accuracy: 0.7901\n",
      "Epoch 405/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4100 - accuracy: 0.8853 - val_loss: 0.8491 - val_accuracy: 0.8395\n",
      "Epoch 406/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3877 - accuracy: 0.8886 - val_loss: 0.8679 - val_accuracy: 0.7778\n",
      "Epoch 407/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4748 - accuracy: 0.8694 - val_loss: 0.7579 - val_accuracy: 0.8395\n",
      "Epoch 408/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3792 - accuracy: 0.8989 - val_loss: 0.6968 - val_accuracy: 0.8395\n",
      "Epoch 409/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3572 - accuracy: 0.9064 - val_loss: 0.6251 - val_accuracy: 0.8642\n",
      "Epoch 410/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3251 - accuracy: 0.9198 - val_loss: 0.6017 - val_accuracy: 0.8519\n",
      "Epoch 411/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2655 - accuracy: 0.9410 - val_loss: 0.5767 - val_accuracy: 0.8519\n",
      "Epoch 412/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2685 - accuracy: 0.9353 - val_loss: 0.6047 - val_accuracy: 0.8642\n",
      "Epoch 413/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2579 - accuracy: 0.9414 - val_loss: 0.6522 - val_accuracy: 0.8272\n",
      "Epoch 414/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2678 - accuracy: 0.9333 - val_loss: 0.5613 - val_accuracy: 0.8642\n",
      "Epoch 415/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2327 - accuracy: 0.9436 - val_loss: 0.5954 - val_accuracy: 0.8519\n",
      "Epoch 416/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2502 - accuracy: 0.9341 - val_loss: 0.6134 - val_accuracy: 0.8519\n",
      "Epoch 417/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1936 - accuracy: 0.9597 - val_loss: 0.6688 - val_accuracy: 0.8272\n",
      "Epoch 418/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2281 - accuracy: 0.9417 - val_loss: 0.7138 - val_accuracy: 0.8395\n",
      "Epoch 419/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2071 - accuracy: 0.9481 - val_loss: 0.6004 - val_accuracy: 0.8395\n",
      "Epoch 420/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2473 - accuracy: 0.9380 - val_loss: 0.6393 - val_accuracy: 0.8395\n",
      "Epoch 421/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2146 - accuracy: 0.9495 - val_loss: 0.5701 - val_accuracy: 0.8519\n",
      "Epoch 422/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2253 - accuracy: 0.9383 - val_loss: 0.6660 - val_accuracy: 0.8642\n",
      "Epoch 423/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2245 - accuracy: 0.9398 - val_loss: 0.6255 - val_accuracy: 0.8519\n",
      "Epoch 424/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1774 - accuracy: 0.9588 - val_loss: 0.6471 - val_accuracy: 0.8519\n",
      "Epoch 425/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2094 - accuracy: 0.9459 - val_loss: 0.6220 - val_accuracy: 0.8519\n",
      "Epoch 426/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2196 - accuracy: 0.9396 - val_loss: 0.7624 - val_accuracy: 0.8025\n",
      "Epoch 427/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2097 - accuracy: 0.9415 - val_loss: 0.7243 - val_accuracy: 0.8148\n",
      "Epoch 428/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1576 - accuracy: 0.9626 - val_loss: 0.6272 - val_accuracy: 0.8642\n",
      "Epoch 429/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1733 - accuracy: 0.9596 - val_loss: 0.6511 - val_accuracy: 0.8642\n",
      "Epoch 430/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1774 - accuracy: 0.9559 - val_loss: 0.6626 - val_accuracy: 0.8519\n",
      "Epoch 431/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2112 - accuracy: 0.9512 - val_loss: 0.7336 - val_accuracy: 0.8395\n",
      "Epoch 432/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2385 - accuracy: 0.9348 - val_loss: 0.5519 - val_accuracy: 0.8765\n",
      "Epoch 433/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2378 - accuracy: 0.9390 - val_loss: 0.6854 - val_accuracy: 0.8765\n",
      "Epoch 434/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2899 - accuracy: 0.9221 - val_loss: 1.0599 - val_accuracy: 0.7531\n",
      "Epoch 435/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3376 - accuracy: 0.9034 - val_loss: 0.9019 - val_accuracy: 0.7901\n",
      "Epoch 436/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.3663 - accuracy: 0.6529 - val_loss: 1.3395 - val_accuracy: 0.6420\n",
      "Epoch 437/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 1.4761 - accuracy: 0.5957 - val_loss: 1.3530 - val_accuracy: 0.6420\n",
      "Epoch 438/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0829 - accuracy: 0.6768 - val_loss: 1.0678 - val_accuracy: 0.7284\n",
      "Epoch 439/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.8512 - accuracy: 0.7317 - val_loss: 0.8805 - val_accuracy: 0.7531\n",
      "Epoch 440/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.6439 - accuracy: 0.8190 - val_loss: 0.9717 - val_accuracy: 0.6914\n",
      "Epoch 441/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.5308 - accuracy: 0.8425 - val_loss: 0.8253 - val_accuracy: 0.8025\n",
      "Epoch 442/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.5449 - accuracy: 0.8533 - val_loss: 0.8751 - val_accuracy: 0.8272\n",
      "Epoch 443/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.4785 - accuracy: 0.8614 - val_loss: 0.7977 - val_accuracy: 0.8148\n",
      "Epoch 444/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3981 - accuracy: 0.8870 - val_loss: 0.7431 - val_accuracy: 0.8272\n",
      "Epoch 445/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3386 - accuracy: 0.9095 - val_loss: 0.7315 - val_accuracy: 0.8395\n",
      "Epoch 446/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3478 - accuracy: 0.8994 - val_loss: 0.7045 - val_accuracy: 0.8519\n",
      "Epoch 447/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3237 - accuracy: 0.9219 - val_loss: 0.6835 - val_accuracy: 0.8519\n",
      "Epoch 448/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2726 - accuracy: 0.9296 - val_loss: 0.7284 - val_accuracy: 0.8519\n",
      "Epoch 449/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2992 - accuracy: 0.9251 - val_loss: 0.7018 - val_accuracy: 0.8148\n",
      "Epoch 450/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3032 - accuracy: 0.9160 - val_loss: 0.7056 - val_accuracy: 0.8148\n",
      "Epoch 451/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3039 - accuracy: 0.9109 - val_loss: 0.5908 - val_accuracy: 0.8889\n",
      "Epoch 452/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2520 - accuracy: 0.9333 - val_loss: 0.6603 - val_accuracy: 0.8642\n",
      "Epoch 453/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2329 - accuracy: 0.9388 - val_loss: 0.6840 - val_accuracy: 0.8272\n",
      "Epoch 454/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2065 - accuracy: 0.9423 - val_loss: 0.6857 - val_accuracy: 0.8642\n",
      "Epoch 455/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2449 - accuracy: 0.9423 - val_loss: 0.7836 - val_accuracy: 0.8519\n",
      "Epoch 456/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3004 - accuracy: 0.9199 - val_loss: 0.7446 - val_accuracy: 0.8395\n",
      "Epoch 457/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2689 - accuracy: 0.9317 - val_loss: 0.7350 - val_accuracy: 0.8519\n",
      "Epoch 458/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2666 - accuracy: 0.9254 - val_loss: 0.8525 - val_accuracy: 0.8148\n",
      "Epoch 459/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6004 - accuracy: 0.8153 - val_loss: 0.9785 - val_accuracy: 0.7407\n",
      "Epoch 460/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.8087 - accuracy: 0.7632 - val_loss: 0.9397 - val_accuracy: 0.7531\n",
      "Epoch 461/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5890 - accuracy: 0.8282 - val_loss: 0.7422 - val_accuracy: 0.8395\n",
      "Epoch 462/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4262 - accuracy: 0.8785 - val_loss: 0.7231 - val_accuracy: 0.8272\n",
      "Epoch 463/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3532 - accuracy: 0.9041 - val_loss: 0.6851 - val_accuracy: 0.8519\n",
      "Epoch 464/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2567 - accuracy: 0.9381 - val_loss: 0.6903 - val_accuracy: 0.8642\n",
      "Epoch 465/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2761 - accuracy: 0.9343 - val_loss: 0.6214 - val_accuracy: 0.8395\n",
      "Epoch 466/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2650 - accuracy: 0.9378 - val_loss: 0.6788 - val_accuracy: 0.8395\n",
      "Epoch 467/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2903 - accuracy: 0.9176 - val_loss: 0.6653 - val_accuracy: 0.8395\n",
      "Epoch 468/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2099 - accuracy: 0.9499 - val_loss: 0.6297 - val_accuracy: 0.8642\n",
      "Epoch 469/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2167 - accuracy: 0.9475 - val_loss: 0.7292 - val_accuracy: 0.8395\n",
      "Epoch 470/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2435 - accuracy: 0.9395 - val_loss: 0.7868 - val_accuracy: 0.8272\n",
      "Epoch 471/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2177 - accuracy: 0.9423 - val_loss: 0.7636 - val_accuracy: 0.8395\n",
      "Epoch 472/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1975 - accuracy: 0.9478 - val_loss: 0.6819 - val_accuracy: 0.8519\n",
      "Epoch 473/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2041 - accuracy: 0.9498 - val_loss: 0.6893 - val_accuracy: 0.8765\n",
      "Epoch 474/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1938 - accuracy: 0.9459 - val_loss: 0.6409 - val_accuracy: 0.8519\n",
      "Epoch 475/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2417 - accuracy: 0.9274 - val_loss: 0.6822 - val_accuracy: 0.8642\n",
      "Epoch 476/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1988 - accuracy: 0.9511 - val_loss: 0.6757 - val_accuracy: 0.8519\n",
      "Epoch 477/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2166 - accuracy: 0.9456 - val_loss: 0.6323 - val_accuracy: 0.8765\n",
      "Epoch 478/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1857 - accuracy: 0.9483 - val_loss: 0.6731 - val_accuracy: 0.8765\n",
      "Epoch 479/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1757 - accuracy: 0.9501 - val_loss: 0.7239 - val_accuracy: 0.8519\n",
      "Epoch 480/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1889 - accuracy: 0.9538 - val_loss: 0.6845 - val_accuracy: 0.8642\n",
      "Epoch 481/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1561 - accuracy: 0.9590 - val_loss: 0.6824 - val_accuracy: 0.8519\n",
      "Epoch 482/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1936 - accuracy: 0.9461 - val_loss: 0.6869 - val_accuracy: 0.8519\n",
      "Epoch 483/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1856 - accuracy: 0.9511 - val_loss: 0.7181 - val_accuracy: 0.8642\n",
      "Epoch 484/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1400 - accuracy: 0.9580 - val_loss: 0.7079 - val_accuracy: 0.8519\n",
      "Epoch 485/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1823 - accuracy: 0.9385 - val_loss: 0.6980 - val_accuracy: 0.8642\n",
      "Epoch 486/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1558 - accuracy: 0.9563 - val_loss: 0.7896 - val_accuracy: 0.8642\n",
      "Epoch 487/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2114 - accuracy: 0.9395 - val_loss: 0.6483 - val_accuracy: 0.8642\n",
      "Epoch 488/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2408 - accuracy: 0.9361 - val_loss: 0.7734 - val_accuracy: 0.8395\n",
      "Epoch 489/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2100 - accuracy: 0.9319 - val_loss: 0.7478 - val_accuracy: 0.8519\n",
      "Epoch 490/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2089 - accuracy: 0.9479 - val_loss: 0.6972 - val_accuracy: 0.8765\n",
      "Epoch 491/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1823 - accuracy: 0.9511 - val_loss: 0.6602 - val_accuracy: 0.8765\n",
      "Epoch 492/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1752 - accuracy: 0.9568 - val_loss: 0.6675 - val_accuracy: 0.8765\n",
      "Epoch 493/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1917 - accuracy: 0.9456 - val_loss: 0.7016 - val_accuracy: 0.8642\n",
      "Epoch 494/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1468 - accuracy: 0.9557 - val_loss: 0.8562 - val_accuracy: 0.8272\n",
      "Epoch 495/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4684 - accuracy: 0.8603 - val_loss: 0.8553 - val_accuracy: 0.8025\n",
      "Epoch 496/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4848 - accuracy: 0.8609 - val_loss: 0.9625 - val_accuracy: 0.8025\n",
      "Epoch 497/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3871 - accuracy: 0.8730 - val_loss: 0.7779 - val_accuracy: 0.8642\n",
      "Epoch 498/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2839 - accuracy: 0.9106 - val_loss: 0.6648 - val_accuracy: 0.8889\n",
      "Epoch 499/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2424 - accuracy: 0.9350 - val_loss: 0.6883 - val_accuracy: 0.8642\n",
      "Epoch 500/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2130 - accuracy: 0.9387 - val_loss: 0.6000 - val_accuracy: 0.9259\n",
      "Epoch 501/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2065 - accuracy: 0.9481 - val_loss: 0.6117 - val_accuracy: 0.8765\n",
      "Epoch 502/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2032 - accuracy: 0.9534 - val_loss: 0.6682 - val_accuracy: 0.8642\n",
      "Epoch 503/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2053 - accuracy: 0.9434 - val_loss: 0.6723 - val_accuracy: 0.8642\n",
      "Epoch 504/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1924 - accuracy: 0.9494 - val_loss: 0.6471 - val_accuracy: 0.8765\n",
      "Epoch 505/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1615 - accuracy: 0.9599 - val_loss: 0.6690 - val_accuracy: 0.8765\n",
      "Epoch 506/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2100 - accuracy: 0.9431 - val_loss: 0.7769 - val_accuracy: 0.8272\n",
      "Epoch 507/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1905 - accuracy: 0.9512 - val_loss: 0.5569 - val_accuracy: 0.9012\n",
      "Epoch 508/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2553 - accuracy: 0.9278 - val_loss: 0.6472 - val_accuracy: 0.8395\n",
      "Epoch 509/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2015 - accuracy: 0.9385 - val_loss: 0.6871 - val_accuracy: 0.8519\n",
      "Epoch 510/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2526 - accuracy: 0.9336 - val_loss: 0.6565 - val_accuracy: 0.8642\n",
      "Epoch 511/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2329 - accuracy: 0.9364 - val_loss: 0.7843 - val_accuracy: 0.8395\n",
      "Epoch 512/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2260 - accuracy: 0.9273 - val_loss: 0.6337 - val_accuracy: 0.8519\n",
      "Epoch 513/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2726 - accuracy: 0.9152 - val_loss: 0.6189 - val_accuracy: 0.8765\n",
      "Epoch 514/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2120 - accuracy: 0.9447 - val_loss: 0.5833 - val_accuracy: 0.8765\n",
      "Epoch 515/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1781 - accuracy: 0.9549 - val_loss: 0.6527 - val_accuracy: 0.8395\n",
      "Epoch 516/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1595 - accuracy: 0.9629 - val_loss: 0.7336 - val_accuracy: 0.8642\n",
      "Epoch 517/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1639 - accuracy: 0.9623 - val_loss: 0.6211 - val_accuracy: 0.8642\n",
      "Epoch 518/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1642 - accuracy: 0.9599 - val_loss: 0.6876 - val_accuracy: 0.8272\n",
      "Epoch 519/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1750 - accuracy: 0.9575 - val_loss: 0.6917 - val_accuracy: 0.8642\n",
      "Epoch 520/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1699 - accuracy: 0.9587 - val_loss: 0.7205 - val_accuracy: 0.8765\n",
      "Epoch 521/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.4308 - accuracy: 0.8719 - val_loss: 0.8279 - val_accuracy: 0.7901\n",
      "Epoch 522/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4484 - accuracy: 0.8671 - val_loss: 0.8512 - val_accuracy: 0.8148\n",
      "Epoch 523/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3547 - accuracy: 0.8906 - val_loss: 0.7619 - val_accuracy: 0.8272\n",
      "Epoch 524/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2402 - accuracy: 0.9267 - val_loss: 0.6776 - val_accuracy: 0.8642\n",
      "Epoch 525/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2674 - accuracy: 0.9265 - val_loss: 0.9179 - val_accuracy: 0.8025\n",
      "Epoch 526/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2937 - accuracy: 0.9149 - val_loss: 0.7851 - val_accuracy: 0.8148\n",
      "Epoch 527/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3511 - accuracy: 0.9032 - val_loss: 0.8949 - val_accuracy: 0.7901\n",
      "Epoch 528/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3994 - accuracy: 0.8910 - val_loss: 0.6939 - val_accuracy: 0.8519\n",
      "Epoch 529/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3824 - accuracy: 0.8950 - val_loss: 0.8742 - val_accuracy: 0.8025\n",
      "Epoch 530/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3135 - accuracy: 0.9167 - val_loss: 0.6957 - val_accuracy: 0.8148\n",
      "Epoch 531/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3231 - accuracy: 0.9081 - val_loss: 0.7468 - val_accuracy: 0.8148\n",
      "Epoch 532/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2669 - accuracy: 0.9178 - val_loss: 0.7003 - val_accuracy: 0.8395\n",
      "Epoch 533/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2117 - accuracy: 0.9383 - val_loss: 0.6637 - val_accuracy: 0.8519\n",
      "Epoch 534/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2155 - accuracy: 0.9503 - val_loss: 0.5501 - val_accuracy: 0.8889\n",
      "Epoch 535/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2595 - accuracy: 0.9334 - val_loss: 0.6356 - val_accuracy: 0.8765\n",
      "Epoch 536/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2329 - accuracy: 0.9406 - val_loss: 0.7992 - val_accuracy: 0.8519\n",
      "Epoch 537/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2469 - accuracy: 0.9276 - val_loss: 0.7181 - val_accuracy: 0.8519\n",
      "Epoch 538/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2463 - accuracy: 0.9347 - val_loss: 0.6937 - val_accuracy: 0.8519\n",
      "Epoch 539/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2014 - accuracy: 0.9444 - val_loss: 0.6541 - val_accuracy: 0.8642\n",
      "Epoch 540/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1952 - accuracy: 0.9529 - val_loss: 0.6397 - val_accuracy: 0.8519\n",
      "Epoch 541/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1881 - accuracy: 0.9529 - val_loss: 0.6170 - val_accuracy: 0.8765\n",
      "Epoch 542/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1706 - accuracy: 0.9589 - val_loss: 0.5687 - val_accuracy: 0.9012\n",
      "Epoch 543/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1718 - accuracy: 0.9577 - val_loss: 0.5946 - val_accuracy: 0.8642\n",
      "Epoch 544/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1710 - accuracy: 0.9568 - val_loss: 0.6267 - val_accuracy: 0.8642\n",
      "Epoch 545/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1816 - accuracy: 0.9465 - val_loss: 0.6527 - val_accuracy: 0.8642\n",
      "Epoch 546/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1540 - accuracy: 0.9565 - val_loss: 0.6657 - val_accuracy: 0.8765\n",
      "Epoch 547/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2046 - accuracy: 0.9356 - val_loss: 0.7121 - val_accuracy: 0.8519\n",
      "Epoch 548/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2308 - accuracy: 0.9378 - val_loss: 0.7208 - val_accuracy: 0.8519\n",
      "Epoch 549/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2661 - accuracy: 0.9190 - val_loss: 0.7423 - val_accuracy: 0.8519\n",
      "Epoch 550/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2777 - accuracy: 0.9298 - val_loss: 0.6368 - val_accuracy: 0.8395\n",
      "Epoch 551/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.3089 - accuracy: 0.9062 - val_loss: 0.6815 - val_accuracy: 0.8765\n",
      "Epoch 552/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2101 - accuracy: 0.9372 - val_loss: 0.7524 - val_accuracy: 0.8765\n",
      "Epoch 553/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1916 - accuracy: 0.9444 - val_loss: 0.6584 - val_accuracy: 0.8889\n",
      "Epoch 554/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1722 - accuracy: 0.9497 - val_loss: 0.6635 - val_accuracy: 0.8519\n",
      "Epoch 555/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1839 - accuracy: 0.9531 - val_loss: 0.7396 - val_accuracy: 0.8519\n",
      "Epoch 556/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1924 - accuracy: 0.9391 - val_loss: 0.7501 - val_accuracy: 0.8519\n",
      "Epoch 557/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1740 - accuracy: 0.9497 - val_loss: 0.6320 - val_accuracy: 0.8889\n",
      "Epoch 558/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1515 - accuracy: 0.9523 - val_loss: 0.6958 - val_accuracy: 0.8395\n",
      "Epoch 559/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1487 - accuracy: 0.9578 - val_loss: 0.6644 - val_accuracy: 0.8765\n",
      "Epoch 560/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1710 - accuracy: 0.9487 - val_loss: 0.7626 - val_accuracy: 0.8519\n",
      "Epoch 561/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1517 - accuracy: 0.9530 - val_loss: 0.7544 - val_accuracy: 0.8519\n",
      "Epoch 562/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1433 - accuracy: 0.9644 - val_loss: 0.6786 - val_accuracy: 0.8765\n",
      "Epoch 563/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1498 - accuracy: 0.9546 - val_loss: 0.6539 - val_accuracy: 0.8642\n",
      "Epoch 564/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1414 - accuracy: 0.9658 - val_loss: 0.6671 - val_accuracy: 0.8642\n",
      "Epoch 565/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1381 - accuracy: 0.9602 - val_loss: 0.6408 - val_accuracy: 0.8765\n",
      "Epoch 566/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1252 - accuracy: 0.9726 - val_loss: 0.6407 - val_accuracy: 0.8765\n",
      "Epoch 567/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1567 - accuracy: 0.9553 - val_loss: 0.6519 - val_accuracy: 0.8765\n",
      "Epoch 568/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1406 - accuracy: 0.9629 - val_loss: 0.5885 - val_accuracy: 0.8889\n",
      "Epoch 569/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1375 - accuracy: 0.9626 - val_loss: 0.5923 - val_accuracy: 0.8889\n",
      "Epoch 570/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1311 - accuracy: 0.9610 - val_loss: 0.5930 - val_accuracy: 0.8889\n",
      "Epoch 571/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1413 - accuracy: 0.9620 - val_loss: 0.5631 - val_accuracy: 0.8889\n",
      "Epoch 572/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1326 - accuracy: 0.9648 - val_loss: 0.5922 - val_accuracy: 0.8889\n",
      "Epoch 573/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1278 - accuracy: 0.9613 - val_loss: 0.5870 - val_accuracy: 0.8889\n",
      "Epoch 574/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1395 - accuracy: 0.9619 - val_loss: 0.5861 - val_accuracy: 0.8765\n",
      "Epoch 575/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1273 - accuracy: 0.9571 - val_loss: 0.5934 - val_accuracy: 0.8889\n",
      "Epoch 576/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1272 - accuracy: 0.9639 - val_loss: 0.6443 - val_accuracy: 0.8765\n",
      "Epoch 577/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1638 - accuracy: 0.9536 - val_loss: 0.6557 - val_accuracy: 0.8765\n",
      "Epoch 578/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1143 - accuracy: 0.9720 - val_loss: 0.6461 - val_accuracy: 0.8765\n",
      "Epoch 579/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1129 - accuracy: 0.9720 - val_loss: 0.5892 - val_accuracy: 0.8889\n",
      "Epoch 580/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1193 - accuracy: 0.9630 - val_loss: 0.5720 - val_accuracy: 0.8889\n",
      "Epoch 581/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1282 - accuracy: 0.9658 - val_loss: 0.6319 - val_accuracy: 0.8889\n",
      "Epoch 582/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1273 - accuracy: 0.9614 - val_loss: 0.6068 - val_accuracy: 0.9012\n",
      "Epoch 583/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1132 - accuracy: 0.9657 - val_loss: 0.9051 - val_accuracy: 0.8025\n",
      "Epoch 584/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4544 - accuracy: 0.8789 - val_loss: 1.1248 - val_accuracy: 0.7654\n",
      "Epoch 585/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.5240 - accuracy: 0.8588 - val_loss: 0.9330 - val_accuracy: 0.8272\n",
      "Epoch 586/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.3898 - accuracy: 0.8976 - val_loss: 0.7602 - val_accuracy: 0.8272\n",
      "Epoch 587/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2292 - accuracy: 0.9312 - val_loss: 0.7655 - val_accuracy: 0.8395\n",
      "Epoch 588/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2225 - accuracy: 0.9400 - val_loss: 0.6484 - val_accuracy: 0.8765\n",
      "Epoch 589/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1700 - accuracy: 0.9464 - val_loss: 0.5883 - val_accuracy: 0.8765\n",
      "Epoch 590/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1472 - accuracy: 0.9523 - val_loss: 0.6715 - val_accuracy: 0.8889\n",
      "Epoch 591/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1772 - accuracy: 0.9513 - val_loss: 0.6987 - val_accuracy: 0.8642\n",
      "Epoch 592/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1724 - accuracy: 0.9574 - val_loss: 0.7044 - val_accuracy: 0.8642\n",
      "Epoch 593/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1752 - accuracy: 0.9416 - val_loss: 0.6012 - val_accuracy: 0.9012\n",
      "Epoch 594/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1962 - accuracy: 0.9387 - val_loss: 0.6112 - val_accuracy: 0.9012\n",
      "Epoch 595/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1854 - accuracy: 0.9451 - val_loss: 0.7127 - val_accuracy: 0.8519\n",
      "Epoch 596/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1665 - accuracy: 0.9595 - val_loss: 0.7251 - val_accuracy: 0.8765\n",
      "Epoch 597/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1800 - accuracy: 0.9507 - val_loss: 0.5827 - val_accuracy: 0.8765\n",
      "Epoch 598/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1250 - accuracy: 0.9668 - val_loss: 0.5561 - val_accuracy: 0.8889\n",
      "Epoch 599/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1670 - accuracy: 0.9472 - val_loss: 0.6028 - val_accuracy: 0.8765\n",
      "Epoch 600/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1445 - accuracy: 0.9592 - val_loss: 0.6170 - val_accuracy: 0.8642\n",
      "Epoch 601/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1544 - accuracy: 0.9586 - val_loss: 0.7097 - val_accuracy: 0.8765\n",
      "Epoch 602/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1970 - accuracy: 0.9444 - val_loss: 0.6786 - val_accuracy: 0.8889\n",
      "Epoch 603/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1375 - accuracy: 0.9623 - val_loss: 0.6755 - val_accuracy: 0.8642\n",
      "Epoch 604/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1392 - accuracy: 0.9654 - val_loss: 0.6625 - val_accuracy: 0.8889\n",
      "Epoch 605/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1271 - accuracy: 0.9696 - val_loss: 0.6567 - val_accuracy: 0.8765\n",
      "Epoch 606/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1265 - accuracy: 0.9682 - val_loss: 0.7289 - val_accuracy: 0.8519\n",
      "Epoch 607/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1727 - accuracy: 0.9559 - val_loss: 0.6756 - val_accuracy: 0.8519\n",
      "Epoch 608/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1651 - accuracy: 0.9538 - val_loss: 0.6233 - val_accuracy: 0.8642\n",
      "Epoch 609/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2561 - accuracy: 0.9291 - val_loss: 1.5746 - val_accuracy: 0.6790\n",
      "Epoch 610/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 1.1056 - accuracy: 0.6979 - val_loss: 1.2270 - val_accuracy: 0.7407\n",
      "Epoch 611/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.6939 - accuracy: 0.7874 - val_loss: 0.9377 - val_accuracy: 0.7654\n",
      "Epoch 612/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4964 - accuracy: 0.8643 - val_loss: 0.7812 - val_accuracy: 0.8148\n",
      "Epoch 613/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4351 - accuracy: 0.8756 - val_loss: 0.7900 - val_accuracy: 0.8272\n",
      "Epoch 614/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3951 - accuracy: 0.8854 - val_loss: 0.7789 - val_accuracy: 0.8148\n",
      "Epoch 615/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3531 - accuracy: 0.8954 - val_loss: 0.6845 - val_accuracy: 0.8519\n",
      "Epoch 616/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3524 - accuracy: 0.9240 - val_loss: 0.7083 - val_accuracy: 0.8148\n",
      "Epoch 617/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3287 - accuracy: 0.9101 - val_loss: 0.7504 - val_accuracy: 0.8395\n",
      "Epoch 618/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2346 - accuracy: 0.9302 - val_loss: 0.6859 - val_accuracy: 0.8642\n",
      "Epoch 619/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2415 - accuracy: 0.9287 - val_loss: 0.7486 - val_accuracy: 0.8395\n",
      "Epoch 620/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3001 - accuracy: 0.9144 - val_loss: 0.7108 - val_accuracy: 0.8272\n",
      "Epoch 621/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2657 - accuracy: 0.9212 - val_loss: 0.8157 - val_accuracy: 0.8272\n",
      "Epoch 622/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2749 - accuracy: 0.9217 - val_loss: 0.6654 - val_accuracy: 0.8765\n",
      "Epoch 623/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2716 - accuracy: 0.9211 - val_loss: 0.7033 - val_accuracy: 0.8395\n",
      "Epoch 624/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2317 - accuracy: 0.9349 - val_loss: 0.6976 - val_accuracy: 0.8519\n",
      "Epoch 625/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2442 - accuracy: 0.9267 - val_loss: 0.7823 - val_accuracy: 0.8272\n",
      "Epoch 626/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2517 - accuracy: 0.9286 - val_loss: 0.8542 - val_accuracy: 0.8272\n",
      "Epoch 627/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3274 - accuracy: 0.8893 - val_loss: 0.7965 - val_accuracy: 0.8025\n",
      "Epoch 628/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2832 - accuracy: 0.9075 - val_loss: 0.7542 - val_accuracy: 0.8148\n",
      "Epoch 629/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2512 - accuracy: 0.9250 - val_loss: 0.7489 - val_accuracy: 0.8642\n",
      "Epoch 630/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2280 - accuracy: 0.9395 - val_loss: 0.6904 - val_accuracy: 0.8519\n",
      "Epoch 631/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1857 - accuracy: 0.9532 - val_loss: 0.7122 - val_accuracy: 0.8642\n",
      "Epoch 632/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2001 - accuracy: 0.9406 - val_loss: 0.6333 - val_accuracy: 0.8642\n",
      "Epoch 633/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1858 - accuracy: 0.9493 - val_loss: 0.6382 - val_accuracy: 0.8765\n",
      "Epoch 634/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1734 - accuracy: 0.9518 - val_loss: 0.7199 - val_accuracy: 0.8519\n",
      "Epoch 635/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1801 - accuracy: 0.9497 - val_loss: 0.7402 - val_accuracy: 0.8272\n",
      "Epoch 636/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1914 - accuracy: 0.9398 - val_loss: 0.7635 - val_accuracy: 0.8148\n",
      "Epoch 637/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1876 - accuracy: 0.9506 - val_loss: 0.7975 - val_accuracy: 0.8519\n",
      "Epoch 638/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4080 - accuracy: 0.8952 - val_loss: 0.6425 - val_accuracy: 0.8519\n",
      "Epoch 639/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2934 - accuracy: 0.9284 - val_loss: 0.6389 - val_accuracy: 0.8765\n",
      "Epoch 640/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2898 - accuracy: 0.9250 - val_loss: 0.6136 - val_accuracy: 0.8642\n",
      "Epoch 641/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2513 - accuracy: 0.9295 - val_loss: 0.6391 - val_accuracy: 0.8642\n",
      "Epoch 642/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2417 - accuracy: 0.9386 - val_loss: 0.6711 - val_accuracy: 0.8765\n",
      "Epoch 643/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2358 - accuracy: 0.9428 - val_loss: 0.6112 - val_accuracy: 0.9012\n",
      "Epoch 644/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2468 - accuracy: 0.9301 - val_loss: 0.7522 - val_accuracy: 0.8642\n",
      "Epoch 645/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1830 - accuracy: 0.9491 - val_loss: 0.6697 - val_accuracy: 0.8889\n",
      "Epoch 646/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2017 - accuracy: 0.9390 - val_loss: 0.6153 - val_accuracy: 0.8889\n",
      "Epoch 647/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1688 - accuracy: 0.9447 - val_loss: 0.6171 - val_accuracy: 0.9012\n",
      "Epoch 648/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1832 - accuracy: 0.9436 - val_loss: 0.6446 - val_accuracy: 0.9012\n",
      "Epoch 649/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1703 - accuracy: 0.9531 - val_loss: 0.6166 - val_accuracy: 0.8765\n",
      "Epoch 650/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2064 - accuracy: 0.9419 - val_loss: 0.6823 - val_accuracy: 0.8889\n",
      "Epoch 651/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2252 - accuracy: 0.9391 - val_loss: 0.7045 - val_accuracy: 0.8642\n",
      "Epoch 652/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1707 - accuracy: 0.9487 - val_loss: 0.6742 - val_accuracy: 0.8765\n",
      "Epoch 653/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1907 - accuracy: 0.9352 - val_loss: 0.5782 - val_accuracy: 0.8889\n",
      "Epoch 654/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1371 - accuracy: 0.9609 - val_loss: 0.6202 - val_accuracy: 0.8889\n",
      "Epoch 655/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1443 - accuracy: 0.9562 - val_loss: 0.6227 - val_accuracy: 0.8642\n",
      "Epoch 656/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1127 - accuracy: 0.9718 - val_loss: 0.5562 - val_accuracy: 0.8889\n",
      "Epoch 657/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1263 - accuracy: 0.9693 - val_loss: 0.5993 - val_accuracy: 0.8765\n",
      "Epoch 658/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1055 - accuracy: 0.9675 - val_loss: 0.6150 - val_accuracy: 0.8642\n",
      "Epoch 659/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1199 - accuracy: 0.9662 - val_loss: 0.8377 - val_accuracy: 0.8642\n",
      "Epoch 660/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2784 - accuracy: 0.9340 - val_loss: 0.8968 - val_accuracy: 0.8272\n",
      "Epoch 661/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.3809 - accuracy: 0.9008 - val_loss: 0.8344 - val_accuracy: 0.8272\n",
      "Epoch 662/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2362 - accuracy: 0.9285 - val_loss: 0.6862 - val_accuracy: 0.8642\n",
      "Epoch 663/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2202 - accuracy: 0.9469 - val_loss: 0.8100 - val_accuracy: 0.8395\n",
      "Epoch 664/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1670 - accuracy: 0.9412 - val_loss: 0.7326 - val_accuracy: 0.8272\n",
      "Epoch 665/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1700 - accuracy: 0.9553 - val_loss: 0.7268 - val_accuracy: 0.8765\n",
      "Epoch 666/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1758 - accuracy: 0.9522 - val_loss: 0.7829 - val_accuracy: 0.8148\n",
      "Epoch 667/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1725 - accuracy: 0.9473 - val_loss: 0.6911 - val_accuracy: 0.8642\n",
      "Epoch 668/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1535 - accuracy: 0.9472 - val_loss: 0.6760 - val_accuracy: 0.8765\n",
      "Epoch 669/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1649 - accuracy: 0.9529 - val_loss: 0.6426 - val_accuracy: 0.8519\n",
      "Epoch 670/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1319 - accuracy: 0.9596 - val_loss: 0.6717 - val_accuracy: 0.8519\n",
      "Epoch 671/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1525 - accuracy: 0.9608 - val_loss: 0.6618 - val_accuracy: 0.8519\n",
      "Epoch 672/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1221 - accuracy: 0.9655 - val_loss: 0.6454 - val_accuracy: 0.8642\n",
      "Epoch 673/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1362 - accuracy: 0.9590 - val_loss: 0.5957 - val_accuracy: 0.8765\n",
      "Epoch 674/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.0993 - accuracy: 0.9783 - val_loss: 0.6554 - val_accuracy: 0.8642\n",
      "Epoch 675/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1103 - accuracy: 0.9721 - val_loss: 0.7080 - val_accuracy: 0.8642\n",
      "Epoch 676/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1815 - accuracy: 0.9431 - val_loss: 0.7156 - val_accuracy: 0.8519\n",
      "Epoch 677/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2211 - accuracy: 0.9354 - val_loss: 0.7361 - val_accuracy: 0.8765\n",
      "Epoch 678/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3296 - accuracy: 0.9041 - val_loss: 0.7054 - val_accuracy: 0.8395\n",
      "Epoch 679/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2869 - accuracy: 0.9121 - val_loss: 0.7289 - val_accuracy: 0.8519\n",
      "Epoch 680/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2335 - accuracy: 0.9371 - val_loss: 1.1924 - val_accuracy: 0.7654\n",
      "Epoch 681/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.4221 - accuracy: 0.8767 - val_loss: 0.7712 - val_accuracy: 0.8395\n",
      "Epoch 682/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2700 - accuracy: 0.9128 - val_loss: 0.7920 - val_accuracy: 0.8148\n",
      "Epoch 683/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2515 - accuracy: 0.9147 - val_loss: 0.9013 - val_accuracy: 0.8272\n",
      "Epoch 684/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2576 - accuracy: 0.9286 - val_loss: 0.6917 - val_accuracy: 0.8519\n",
      "Epoch 685/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1819 - accuracy: 0.9385 - val_loss: 0.6840 - val_accuracy: 0.8395\n",
      "Epoch 686/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1427 - accuracy: 0.9629 - val_loss: 0.6730 - val_accuracy: 0.8395\n",
      "Epoch 687/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1446 - accuracy: 0.9557 - val_loss: 0.6888 - val_accuracy: 0.8519\n",
      "Epoch 688/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1413 - accuracy: 0.9563 - val_loss: 0.6979 - val_accuracy: 0.8765\n",
      "Epoch 689/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1513 - accuracy: 0.9617 - val_loss: 0.6571 - val_accuracy: 0.8642\n",
      "Epoch 690/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1367 - accuracy: 0.9708 - val_loss: 0.6889 - val_accuracy: 0.8765\n",
      "Epoch 691/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3649 - accuracy: 0.8968 - val_loss: 0.9491 - val_accuracy: 0.7654\n",
      "Epoch 692/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3862 - accuracy: 0.8953 - val_loss: 0.7152 - val_accuracy: 0.8519\n",
      "Epoch 693/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2010 - accuracy: 0.9522 - val_loss: 0.7262 - val_accuracy: 0.8395\n",
      "Epoch 694/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2478 - accuracy: 0.9327 - val_loss: 0.6911 - val_accuracy: 0.8272\n",
      "Epoch 695/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1780 - accuracy: 0.9477 - val_loss: 0.7214 - val_accuracy: 0.8272\n",
      "Epoch 696/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1439 - accuracy: 0.9526 - val_loss: 0.7099 - val_accuracy: 0.8519\n",
      "Epoch 697/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1344 - accuracy: 0.9648 - val_loss: 0.6071 - val_accuracy: 0.8642\n",
      "Epoch 698/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1194 - accuracy: 0.9770 - val_loss: 0.6449 - val_accuracy: 0.8765\n",
      "Epoch 699/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1439 - accuracy: 0.9634 - val_loss: 0.6829 - val_accuracy: 0.8642\n",
      "Epoch 700/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1245 - accuracy: 0.9678 - val_loss: 0.6849 - val_accuracy: 0.8765\n",
      "Epoch 701/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1192 - accuracy: 0.9715 - val_loss: 0.6778 - val_accuracy: 0.8765\n",
      "Epoch 702/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1754 - accuracy: 0.9526 - val_loss: 0.6480 - val_accuracy: 0.8765\n",
      "Epoch 703/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1507 - accuracy: 0.9575 - val_loss: 0.7036 - val_accuracy: 0.8642\n",
      "Epoch 704/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1308 - accuracy: 0.9664 - val_loss: 0.7000 - val_accuracy: 0.8642\n",
      "Epoch 705/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1405 - accuracy: 0.9547 - val_loss: 0.7161 - val_accuracy: 0.8519\n",
      "Epoch 706/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1584 - accuracy: 0.9575 - val_loss: 0.7527 - val_accuracy: 0.8519\n",
      "Epoch 707/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1549 - accuracy: 0.9552 - val_loss: 0.6458 - val_accuracy: 0.8642\n",
      "Epoch 708/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1283 - accuracy: 0.9605 - val_loss: 0.6213 - val_accuracy: 0.8889\n",
      "Epoch 709/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1429 - accuracy: 0.9573 - val_loss: 0.7387 - val_accuracy: 0.8765\n",
      "Epoch 710/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1593 - accuracy: 0.9517 - val_loss: 0.6945 - val_accuracy: 0.8642\n",
      "Epoch 711/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1499 - accuracy: 0.9628 - val_loss: 0.6438 - val_accuracy: 0.8642\n",
      "Epoch 712/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1528 - accuracy: 0.9520 - val_loss: 0.6683 - val_accuracy: 0.8889\n",
      "Epoch 713/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1243 - accuracy: 0.9626 - val_loss: 0.6133 - val_accuracy: 0.8889\n",
      "Epoch 714/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1140 - accuracy: 0.9662 - val_loss: 0.5959 - val_accuracy: 0.8765\n",
      "Epoch 715/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0919 - accuracy: 0.9733 - val_loss: 0.6413 - val_accuracy: 0.8765\n",
      "Epoch 716/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1535 - accuracy: 0.9516 - val_loss: 0.6464 - val_accuracy: 0.8765\n",
      "Epoch 717/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1869 - accuracy: 0.9533 - val_loss: 0.5788 - val_accuracy: 0.8765\n",
      "Epoch 718/800\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1260 - accuracy: 0.9627 - val_loss: 0.6721 - val_accuracy: 0.8519\n",
      "Epoch 719/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1590 - accuracy: 0.9550 - val_loss: 0.6410 - val_accuracy: 0.8642\n",
      "Epoch 720/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1404 - accuracy: 0.9599 - val_loss: 0.5965 - val_accuracy: 0.8889\n",
      "Epoch 721/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1155 - accuracy: 0.9728 - val_loss: 0.6524 - val_accuracy: 0.8889\n",
      "Epoch 722/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0986 - accuracy: 0.9713 - val_loss: 0.6589 - val_accuracy: 0.8765\n",
      "Epoch 723/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1183 - accuracy: 0.9698 - val_loss: 0.6231 - val_accuracy: 0.8889\n",
      "Epoch 724/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1116 - accuracy: 0.9708 - val_loss: 0.6927 - val_accuracy: 0.8642\n",
      "Epoch 725/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1323 - accuracy: 0.9638 - val_loss: 0.7005 - val_accuracy: 0.8395\n",
      "Epoch 726/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1494 - accuracy: 0.9625 - val_loss: 0.8272 - val_accuracy: 0.8642\n",
      "Epoch 727/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1569 - accuracy: 0.9505 - val_loss: 0.7087 - val_accuracy: 0.8765\n",
      "Epoch 728/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1540 - accuracy: 0.9536 - val_loss: 0.7233 - val_accuracy: 0.8642\n",
      "Epoch 729/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1346 - accuracy: 0.9611 - val_loss: 0.7801 - val_accuracy: 0.8272\n",
      "Epoch 730/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1244 - accuracy: 0.9661 - val_loss: 0.7062 - val_accuracy: 0.8765\n",
      "Epoch 731/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1300 - accuracy: 0.9660 - val_loss: 0.7252 - val_accuracy: 0.8765\n",
      "Epoch 732/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0987 - accuracy: 0.9757 - val_loss: 0.7326 - val_accuracy: 0.8765\n",
      "Epoch 733/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0720 - accuracy: 0.9848 - val_loss: 0.6935 - val_accuracy: 0.8765\n",
      "Epoch 734/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0876 - accuracy: 0.9773 - val_loss: 0.8485 - val_accuracy: 0.8519\n",
      "Epoch 735/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1223 - accuracy: 0.9748 - val_loss: 0.7857 - val_accuracy: 0.8519\n",
      "Epoch 736/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1746 - accuracy: 0.9403 - val_loss: 0.8053 - val_accuracy: 0.8642\n",
      "Epoch 737/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3561 - accuracy: 0.8978 - val_loss: 0.8042 - val_accuracy: 0.8642\n",
      "Epoch 738/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.4261 - accuracy: 0.8774 - val_loss: 1.0102 - val_accuracy: 0.7531\n",
      "Epoch 739/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.1290 - accuracy: 0.7143 - val_loss: 0.9574 - val_accuracy: 0.7778\n",
      "Epoch 740/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.7944 - accuracy: 0.7921 - val_loss: 0.7037 - val_accuracy: 0.8148\n",
      "Epoch 741/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5650 - accuracy: 0.8735 - val_loss: 0.6469 - val_accuracy: 0.8519\n",
      "Epoch 742/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4558 - accuracy: 0.8840 - val_loss: 0.6586 - val_accuracy: 0.8148\n",
      "Epoch 743/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4504 - accuracy: 0.8764 - val_loss: 0.6428 - val_accuracy: 0.8519\n",
      "Epoch 744/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4390 - accuracy: 0.8782 - val_loss: 0.6245 - val_accuracy: 0.8642\n",
      "Epoch 745/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5845 - accuracy: 0.8231 - val_loss: 0.7854 - val_accuracy: 0.8395\n",
      "Epoch 746/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.6650 - accuracy: 0.8064 - val_loss: 0.7547 - val_accuracy: 0.8148\n",
      "Epoch 747/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.5624 - accuracy: 0.8289 - val_loss: 0.8149 - val_accuracy: 0.8148\n",
      "Epoch 748/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3622 - accuracy: 0.9037 - val_loss: 0.8243 - val_accuracy: 0.8148\n",
      "Epoch 749/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.3261 - accuracy: 0.9048 - val_loss: 0.7609 - val_accuracy: 0.8519\n",
      "Epoch 750/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2747 - accuracy: 0.9112 - val_loss: 0.6663 - val_accuracy: 0.8642\n",
      "Epoch 751/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2232 - accuracy: 0.9364 - val_loss: 0.6778 - val_accuracy: 0.8642\n",
      "Epoch 752/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2349 - accuracy: 0.9224 - val_loss: 0.6688 - val_accuracy: 0.8642\n",
      "Epoch 753/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2277 - accuracy: 0.9358 - val_loss: 0.6505 - val_accuracy: 0.8765\n",
      "Epoch 754/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2164 - accuracy: 0.9347 - val_loss: 0.6369 - val_accuracy: 0.8765\n",
      "Epoch 755/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1900 - accuracy: 0.9439 - val_loss: 0.6588 - val_accuracy: 0.8889\n",
      "Epoch 756/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1981 - accuracy: 0.9413 - val_loss: 0.6449 - val_accuracy: 0.8642\n",
      "Epoch 757/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1836 - accuracy: 0.9482 - val_loss: 0.6445 - val_accuracy: 0.8642\n",
      "Epoch 758/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2014 - accuracy: 0.9329 - val_loss: 0.6714 - val_accuracy: 0.8642\n",
      "Epoch 759/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1513 - accuracy: 0.9628 - val_loss: 0.6546 - val_accuracy: 0.8889\n",
      "Epoch 760/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1643 - accuracy: 0.9535 - val_loss: 0.7087 - val_accuracy: 0.8642\n",
      "Epoch 761/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1714 - accuracy: 0.9516 - val_loss: 0.6541 - val_accuracy: 0.8889\n",
      "Epoch 762/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1727 - accuracy: 0.9528 - val_loss: 0.6532 - val_accuracy: 0.8765\n",
      "Epoch 763/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1763 - accuracy: 0.9490 - val_loss: 0.6704 - val_accuracy: 0.8765\n",
      "Epoch 764/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1512 - accuracy: 0.9548 - val_loss: 0.6695 - val_accuracy: 0.8889\n",
      "Epoch 765/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1405 - accuracy: 0.9654 - val_loss: 0.6591 - val_accuracy: 0.8889\n",
      "Epoch 766/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1748 - accuracy: 0.9596 - val_loss: 0.6900 - val_accuracy: 0.8889\n",
      "Epoch 767/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1735 - accuracy: 0.9494 - val_loss: 0.6653 - val_accuracy: 0.8889\n",
      "Epoch 768/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1612 - accuracy: 0.9597 - val_loss: 0.5731 - val_accuracy: 0.9012\n",
      "Epoch 769/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1552 - accuracy: 0.9535 - val_loss: 0.6228 - val_accuracy: 0.9012\n",
      "Epoch 770/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1262 - accuracy: 0.9676 - val_loss: 0.6630 - val_accuracy: 0.8889\n",
      "Epoch 771/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1287 - accuracy: 0.9655 - val_loss: 0.6992 - val_accuracy: 0.8765\n",
      "Epoch 772/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1393 - accuracy: 0.9581 - val_loss: 0.6822 - val_accuracy: 0.8765\n",
      "Epoch 773/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1272 - accuracy: 0.9698 - val_loss: 0.7028 - val_accuracy: 0.8765\n",
      "Epoch 774/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1273 - accuracy: 0.9689 - val_loss: 0.7246 - val_accuracy: 0.8642\n",
      "Epoch 775/800\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.1415 - accuracy: 0.9624 - val_loss: 0.6925 - val_accuracy: 0.8765\n",
      "Epoch 776/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1207 - accuracy: 0.9722 - val_loss: 0.7139 - val_accuracy: 0.8765\n",
      "Epoch 777/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1050 - accuracy: 0.9762 - val_loss: 0.7077 - val_accuracy: 0.8642\n",
      "Epoch 778/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1371 - accuracy: 0.9592 - val_loss: 0.6653 - val_accuracy: 0.8765\n",
      "Epoch 779/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1213 - accuracy: 0.9690 - val_loss: 0.6589 - val_accuracy: 0.8889\n",
      "Epoch 780/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1549 - accuracy: 0.9574 - val_loss: 0.6794 - val_accuracy: 0.8889\n",
      "Epoch 781/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1656 - accuracy: 0.9574 - val_loss: 0.6838 - val_accuracy: 0.8765\n",
      "Epoch 782/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1352 - accuracy: 0.9682 - val_loss: 0.6959 - val_accuracy: 0.8765\n",
      "Epoch 783/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1228 - accuracy: 0.9698 - val_loss: 0.7005 - val_accuracy: 0.8889\n",
      "Epoch 784/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1129 - accuracy: 0.9661 - val_loss: 0.7111 - val_accuracy: 0.8765\n",
      "Epoch 785/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1173 - accuracy: 0.9695 - val_loss: 0.6347 - val_accuracy: 0.9012\n",
      "Epoch 786/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1186 - accuracy: 0.9665 - val_loss: 0.7544 - val_accuracy: 0.8765\n",
      "Epoch 787/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1617 - accuracy: 0.9566 - val_loss: 0.6930 - val_accuracy: 0.8765\n",
      "Epoch 788/800\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1381 - accuracy: 0.9644 - val_loss: 0.8623 - val_accuracy: 0.8519\n",
      "Epoch 789/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1760 - accuracy: 0.9458 - val_loss: 0.6432 - val_accuracy: 0.9012\n",
      "Epoch 790/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1251 - accuracy: 0.9646 - val_loss: 0.6346 - val_accuracy: 0.8889\n",
      "Epoch 791/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1550 - accuracy: 0.9567 - val_loss: 0.6077 - val_accuracy: 0.8642\n",
      "Epoch 792/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1128 - accuracy: 0.9688 - val_loss: 0.7033 - val_accuracy: 0.9012\n",
      "Epoch 793/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1085 - accuracy: 0.9717 - val_loss: 0.6571 - val_accuracy: 0.9012\n",
      "Epoch 794/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1096 - accuracy: 0.9660 - val_loss: 0.6896 - val_accuracy: 0.8889\n",
      "Epoch 795/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1079 - accuracy: 0.9723 - val_loss: 0.7095 - val_accuracy: 0.9012\n",
      "Epoch 796/800\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1133 - accuracy: 0.9721 - val_loss: 0.7009 - val_accuracy: 0.8765\n",
      "Epoch 797/800\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1088 - accuracy: 0.9747 - val_loss: 0.7571 - val_accuracy: 0.8642\n",
      "Epoch 798/800\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1127 - accuracy: 0.9715 - val_loss: 0.7546 - val_accuracy: 0.8889\n",
      "Epoch 799/800\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1273 - accuracy: 0.9635 - val_loss: 0.7376 - val_accuracy: 0.8765\n",
      "Epoch 800/800\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.0998 - accuracy: 0.9733 - val_loss: 0.7329 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "checkpoint_filepath = 'Checkpoints/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "gestures = model.fit(x = x_train,\n",
    "            y = y_train,\n",
    "            epochs=800,\n",
    "            validation_split=0.1, #split 10% of the trainning set for the validation set,\n",
    "            batch_size=80,\n",
    "            callbacks=[model_checkpoint_callback],\n",
    "            shuffle=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KikcQb9ZpuLB",
   "metadata": {
    "id": "KikcQb9ZpuLB"
   },
   "outputs": [],
   "source": [
    "# model.save(dir_path + 'Models/gestures.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integrated-optimization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "integrated-optimization",
    "outputId": "cba6efac-b5a4-4da8-e26e-8e8392b0087f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.6697 - accuracy: 0.8535\n",
      "test loss, test acc: [0.6696683764457703, 0.8534704446792603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./drive/MyDrive/Models/gestures/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./drive/MyDrive/Models/gestures/assets\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=80)\n",
    "print(\"test loss, test acc:\", results)\n",
    "model.save(dir_path + 'Models/gestures', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hFsQ_tEXw8WX",
   "metadata": {
    "id": "hFsQ_tEXw8WX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 31)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-89cddc001a99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Models/gestures'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluate on test data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test loss, test acc:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\tranv\\anaconda3\\envs\\baka\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 31)\n"
     ]
    }
   ],
   "source": [
    "# new_model = load_model(dir_path + 'Models/gestures.h5')\n",
    "# print(\"Evaluate on test data\")\n",
    "# results = new_model.evaluate(x_test, y_test, batch_size=80)\n",
    "# print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "feature_computation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feature_computation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "caring-species"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Bidirectional\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
        "# dir_path = './' #local\n",
        "dir_path = './drive/MyDrive/BAKA/' #colab"
      ],
      "id": "caring-species",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KstfPbJfzIAV",
        "outputId": "16198b7e-b631-4183-e29c-23d3e85c86a1"
      },
      "source": [
        "#uncomment in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', sep=' ', index_col=False )\n",
        "# test = np.genfromtxt(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', delimiter=' ',dtype='float64')\n",
        "df = pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', header=None, sep=' ')\n",
        "# df.drop(df.index[60:])\n",
        "# filler = np.zeros((100-len(df), 31))\n",
        "# df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "# df\n",
        "if len(df.columns) > 31:\n",
        "  df = df.drop(columns=[31])\n",
        "# df = df.drop(df.index[60:])\n",
        "# df\n",
        "# sp_df = np.array_split(df, 2)\n",
        "# sp_df[0]"
      ],
      "id": "KstfPbJfzIAV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LynMzTXVtjh_"
      },
      "source": [
        "# for i in ['6']:\n",
        "#     samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
        "#     num_tests = int(len(samples)/5);\n",
        "#     shuffle(samples, random_state = 0)\n",
        "#     for k in range(0, len(samples)):\n",
        "# #         df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
        "#         df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "#         df = df.drop(df.index[60:])\n",
        "#         if len(df.columns) > 31:\n",
        "#           df = df.drop(columns=[31])\n",
        "#         if df.isnull().values.any():\n",
        "#           print(i, \" \", samples[k])\n",
        "#         print(samples[k])\n",
        "#         display(df)\n",
        "#         # # if len(df) < 100:\n",
        "#         # #     filler = np.zeros((100-len(df), 31))\n",
        "#         # #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "#         # x_test.append(df.to_numpy())\n",
        "#         # y_test.append(int(i));"
      ],
      "id": "LynMzTXVtjh_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "signal-friendly",
        "outputId": "d7815457-a027-4c64-a246-077d93ffa470"
      },
      "source": [
        "files = os.listdir(dir_path + 'DataCollection')\n",
        "files"
      ],
      "id": "signal-friendly",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4', '7', '8', '0', '5', '2', '3', '6', '1', '9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "annoying-rotation",
        "outputId": "94eb5817-b7be-47bb-d154-834dc3a334f6"
      },
      "source": [
        "x_train = [];\n",
        "y_train = [];\n",
        "\n",
        "x_test = [];\n",
        "y_test = [];\n",
        "for i in files:\n",
        "    samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
        "    num_tests = int(len(samples)/5);\n",
        "    shuffle(samples, random_state = 0)\n",
        "    for k in range(0, num_tests):\n",
        "#         df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        # df = df.drop(df.index[60:])\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_test.append(df.to_numpy())\n",
        "        y_test.append(int(i));\n",
        "    \n",
        "    for k in range(num_tests, len(samples)):\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        # df = df.drop(df.index[60:])\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # df = df.drop(df.index[100:])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_train.append(df.to_numpy())\n",
        "        y_train.append(int(i));\n",
        "    \n",
        "    print(len(samples), ' ', num_tests, ' ', len(samples)- num_tests)\n",
        "# print(len(x_train))\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train);\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n"
      ],
      "id": "annoying-rotation",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "204   40   164\n",
            "264   52   212\n",
            "233   46   187\n",
            "253   50   203\n",
            "254   50   204\n",
            "320   64   256\n",
            "285   57   228\n",
            "266   53   213\n",
            "319   63   256\n",
            "259   51   208\n",
            "x_train.shape:  (2131, 90, 31)\n",
            "y_train.shiape:  (2131,)\n",
            "x_test.shape:  (526, 90, 31)\n",
            "y_test.shape:  (526,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_7kAXmt41Kf"
      },
      "source": [
        ""
      ],
      "id": "n_7kAXmt41Kf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orange-character",
        "outputId": "e5a5fae5-7597-4fb5-df0a-0d206bb33889"
      },
      "source": [
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "\n"
      ],
      "id": "orange-character",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (2131, 90, 31)\n",
            "y_train.shiape:  (2131,)\n",
            "x_test.shape:  (526, 90, 31)\n",
            "y_test.shape:  (526,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-cheat"
      },
      "source": [
        "def scale_data(data, min_max_scaler):\n",
        "    for i in range(len(data)):\n",
        "        data[i] = min_max_scaler.transform(data[i])\n",
        "    return data"
      ],
      "id": "sensitive-cheat",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broke-sailing"
      },
      "source": [
        "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_train.shape\n",
        "x_train = np.reshape(x_train, newshape=(-1, num_features))\n",
        "x_train = min_max_scaler.fit_transform(x_train)\n",
        "x_train = np.reshape(x_train, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_test.shape\n",
        "x_test = np.reshape(x_test, newshape=(-1, num_features))\n",
        "x_test = min_max_scaler.transform(x_test)\n",
        "x_test = np.reshape(x_test, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_test, y_test = shuffle(x_test, y_test, random_state=0)\n"
      ],
      "id": "broke-sailing",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "discrete-kansas",
        "outputId": "24e79cc9-6982-423d-ea54-5ce21f70bf65"
      },
      "source": [
        "# x_train = np.delete(x_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "# y_train = np.delete(y_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "# print(y_train)\n",
        "# print(\"\\n\")\n",
        "# print(y_test)\n",
        "\n",
        "# y_train = y_train.astype('int')\n",
        "\n",
        "# print(y_train)\n"
      ],
      "id": "discrete-kansas",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (2131, 90, 31)\n",
            "y_train.shiape:  (2131,)\n",
            "x_test.shape:  (526, 90, 31)\n",
            "y_test.shape:  (526,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhabYU0vjbLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2bd962-dd11-4c71-b234-a95d6ac144bf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=90, return_sequences=True ,dtype='float64'),input_shape=x_train.shape[1:],dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Bidirectional(LSTM(units=90 ,dtype='float64') ,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "# model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "model.add(Dense(len(files), activation='softmax',dtype='float64'))\n",
        "model.summary()"
      ],
      "id": "lhabYU0vjbLQ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 90, 180)           87840     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 90, 180)           720       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 90, 180)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 180)               195120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 180)               720       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1810      \n",
            "=================================================================\n",
            "Total params: 286,210\n",
            "Trainable params: 285,490\n",
            "Non-trainable params: 720\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-mystery"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(LSTM(units=60, input_shape=x_train.shape[1:], return_sequences=True,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60, return_sequences=True ,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60, return_sequences=True ,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "# model.add(Dense(7, activation='softmax',dtype='float64'))\n",
        "# model.summary()"
      ],
      "id": "senior-mystery",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "after-sperm",
        "outputId": "a23c0e33-5022-4ebc-a6e2-382741794907"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-5)\n",
        "\n",
        "checkpoint_filepath = dir_path + 'Checkpoints/'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "\n",
        "gestures = model.fit(x = x_train,\n",
        "            y = y_train,\n",
        "            epochs=200,\n",
        "            validation_split=0.1, #split 10% of the trainning set for the validation set,\n",
        "            batch_size=24,\n",
        "            callbacks=[model_checkpoint_callback],\n",
        "            shuffle=True\n",
        "         )"
      ],
      "id": "after-sperm",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "80/80 [==============================] - 14s 62ms/step - loss: 2.8237 - accuracy: 0.2514 - val_loss: 2.1176 - val_accuracy: 0.2944\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 1.5352 - accuracy: 0.5149 - val_loss: 1.6264 - val_accuracy: 0.5701\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.9965 - accuracy: 0.6667 - val_loss: 0.9356 - val_accuracy: 0.8271\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.7138 - accuracy: 0.7621 - val_loss: 0.4677 - val_accuracy: 0.9065\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.5529 - accuracy: 0.8211 - val_loss: 0.2229 - val_accuracy: 0.9626\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.4240 - accuracy: 0.8581 - val_loss: 0.0902 - val_accuracy: 0.9766\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.3468 - accuracy: 0.8925 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.2904 - accuracy: 0.9087 - val_loss: 0.0522 - val_accuracy: 0.9860\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.2640 - accuracy: 0.9124 - val_loss: 0.0544 - val_accuracy: 0.9813\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.2396 - accuracy: 0.9275 - val_loss: 0.0481 - val_accuracy: 0.9813\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.2035 - accuracy: 0.9421 - val_loss: 0.0750 - val_accuracy: 0.9720\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.1678 - accuracy: 0.9473 - val_loss: 0.1468 - val_accuracy: 0.9533\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1619 - accuracy: 0.9504 - val_loss: 0.0484 - val_accuracy: 0.9860\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1500 - accuracy: 0.9536 - val_loss: 0.0396 - val_accuracy: 0.9907\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1590 - accuracy: 0.9515 - val_loss: 0.0181 - val_accuracy: 0.9907\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1317 - accuracy: 0.9604 - val_loss: 0.0354 - val_accuracy: 0.9953\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1174 - accuracy: 0.9656 - val_loss: 0.0389 - val_accuracy: 0.9907\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1239 - accuracy: 0.9692 - val_loss: 0.0369 - val_accuracy: 0.9907\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1238 - accuracy: 0.9588 - val_loss: 0.0402 - val_accuracy: 0.9907\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0986 - accuracy: 0.9713 - val_loss: 0.1000 - val_accuracy: 0.9766\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1071 - accuracy: 0.9682 - val_loss: 0.0184 - val_accuracy: 0.9953\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 0.1090 - val_accuracy: 0.9720\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1019 - accuracy: 0.9724 - val_loss: 0.0533 - val_accuracy: 0.9907\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0919 - accuracy: 0.9703 - val_loss: 0.0520 - val_accuracy: 0.9907\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0790 - accuracy: 0.9755 - val_loss: 0.0281 - val_accuracy: 0.9953\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 0.0327 - val_accuracy: 0.9907\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0734 - accuracy: 0.9765 - val_loss: 0.0480 - val_accuracy: 0.9907\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0829 - accuracy: 0.9776 - val_loss: 0.0494 - val_accuracy: 0.9907\n",
            "Epoch 29/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.0601 - val_accuracy: 0.9907\n",
            "Epoch 30/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 0.0220 - val_accuracy: 0.9953\n",
            "Epoch 31/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.0289 - val_accuracy: 0.9907\n",
            "Epoch 32/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0680 - accuracy: 0.9807 - val_loss: 0.0741 - val_accuracy: 0.9860\n",
            "Epoch 33/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0626 - accuracy: 0.9797 - val_loss: 0.0201 - val_accuracy: 0.9953\n",
            "Epoch 34/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0647 - accuracy: 0.9786 - val_loss: 0.0379 - val_accuracy: 0.9907\n",
            "Epoch 35/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0603 - accuracy: 0.9849 - val_loss: 0.0196 - val_accuracy: 0.9953\n",
            "Epoch 36/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0628 - accuracy: 0.9817 - val_loss: 0.0185 - val_accuracy: 0.9907\n",
            "Epoch 37/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0556 - accuracy: 0.9807 - val_loss: 0.0330 - val_accuracy: 0.9953\n",
            "Epoch 38/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0584 - accuracy: 0.9854 - val_loss: 0.0350 - val_accuracy: 0.9907\n",
            "Epoch 39/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0555 - accuracy: 0.9828 - val_loss: 0.0253 - val_accuracy: 0.9953\n",
            "Epoch 40/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0699 - accuracy: 0.9823 - val_loss: 0.0773 - val_accuracy: 0.9766\n",
            "Epoch 41/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0507 - accuracy: 0.9849 - val_loss: 0.0288 - val_accuracy: 0.9953\n",
            "Epoch 42/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0489 - accuracy: 0.9828 - val_loss: 0.0210 - val_accuracy: 0.9953\n",
            "Epoch 43/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0565 - accuracy: 0.9844 - val_loss: 0.0353 - val_accuracy: 0.9953\n",
            "Epoch 44/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0606 - accuracy: 0.9828 - val_loss: 0.0468 - val_accuracy: 0.9907\n",
            "Epoch 45/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.0263 - val_accuracy: 0.9907\n",
            "Epoch 46/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0058 - val_accuracy: 0.9953\n",
            "Epoch 47/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.0550 - val_accuracy: 0.9907\n",
            "Epoch 48/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.0492 - val_accuracy: 0.9907\n",
            "Epoch 49/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.0514 - val_accuracy: 0.9953\n",
            "Epoch 50/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0136 - val_accuracy: 0.9953\n",
            "Epoch 51/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.1079 - val_accuracy: 0.9720\n",
            "Epoch 53/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 0.0244 - val_accuracy: 0.9953\n",
            "Epoch 54/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0221 - val_accuracy: 0.9953\n",
            "Epoch 55/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 0.0168 - val_accuracy: 0.9953\n",
            "Epoch 56/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0435 - accuracy: 0.9906 - val_loss: 0.0403 - val_accuracy: 0.9907\n",
            "Epoch 58/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.0255 - val_accuracy: 0.9953\n",
            "Epoch 59/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0229 - val_accuracy: 0.9953\n",
            "Epoch 60/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.0058 - val_accuracy: 0.9953\n",
            "Epoch 62/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.0257 - val_accuracy: 0.9953\n",
            "Epoch 63/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
            "Epoch 64/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0304 - accuracy: 0.9922 - val_loss: 0.0426 - val_accuracy: 0.9907\n",
            "Epoch 65/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0252 - accuracy: 0.9937 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0156 - val_accuracy: 0.9907\n",
            "Epoch 67/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0180 - val_accuracy: 0.9907\n",
            "Epoch 68/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.0286 - val_accuracy: 0.9907\n",
            "Epoch 69/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 0.0182 - val_accuracy: 0.9953\n",
            "Epoch 70/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0269 - val_accuracy: 0.9953\n",
            "Epoch 71/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.0061 - val_accuracy: 0.9953\n",
            "Epoch 72/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0304 - val_accuracy: 0.9953\n",
            "Epoch 74/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.0074 - val_accuracy: 0.9953\n",
            "Epoch 75/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0288 - val_accuracy: 0.9953\n",
            "Epoch 76/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.0416 - val_accuracy: 0.9953\n",
            "Epoch 77/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.0217 - val_accuracy: 0.9953\n",
            "Epoch 78/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0473 - val_accuracy: 0.9907\n",
            "Epoch 79/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0373 - val_accuracy: 0.9907\n",
            "Epoch 80/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.0353 - val_accuracy: 0.9953\n",
            "Epoch 81/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.0118 - val_accuracy: 0.9953\n",
            "Epoch 82/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0255 - val_accuracy: 0.9907\n",
            "Epoch 83/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0951 - val_accuracy: 0.9766\n",
            "Epoch 85/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0228 - val_accuracy: 0.9953\n",
            "Epoch 86/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 0.0301 - val_accuracy: 0.9953\n",
            "Epoch 87/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.0049 - val_accuracy: 0.9953\n",
            "Epoch 88/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 0.0338 - val_accuracy: 0.9907\n",
            "Epoch 89/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.1058 - val_accuracy: 0.9860\n",
            "Epoch 90/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 1.6298e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.0090 - val_accuracy: 0.9953\n",
            "Epoch 92/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0355 - val_accuracy: 0.9953\n",
            "Epoch 93/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0225 - val_accuracy: 0.9953\n",
            "Epoch 94/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0214 - val_accuracy: 0.9953\n",
            "Epoch 95/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0271 - accuracy: 0.9943 - val_loss: 0.3715 - val_accuracy: 0.9252\n",
            "Epoch 96/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0334 - accuracy: 0.9922 - val_loss: 0.1526 - val_accuracy: 0.9533\n",
            "Epoch 97/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0338 - accuracy: 0.9906 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0126 - val_accuracy: 0.9953\n",
            "Epoch 100/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0488 - val_accuracy: 0.9907\n",
            "Epoch 101/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
            "Epoch 102/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 4.5540e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0085 - val_accuracy: 0.9953\n",
            "Epoch 104/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0290 - val_accuracy: 0.9907\n",
            "Epoch 105/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0776 - val_accuracy: 0.9766\n",
            "Epoch 106/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0114 - val_accuracy: 0.9953\n",
            "Epoch 107/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0360 - val_accuracy: 0.9813\n",
            "Epoch 108/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1352 - val_accuracy: 0.9673\n",
            "Epoch 109/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0054 - val_accuracy: 0.9953\n",
            "Epoch 110/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.2242 - val_accuracy: 0.9486\n",
            "Epoch 111/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0122 - accuracy: 0.9948 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9953\n",
            "Epoch 113/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.0313 - val_accuracy: 0.9953\n",
            "Epoch 114/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0446 - val_accuracy: 0.9813\n",
            "Epoch 115/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 116/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0128 - val_accuracy: 0.9953\n",
            "Epoch 117/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0255 - val_accuracy: 0.9953\n",
            "Epoch 118/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0243 - val_accuracy: 0.9953\n",
            "Epoch 119/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0111 - val_accuracy: 0.9953\n",
            "Epoch 120/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 8.3478e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 6.2341e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0370 - val_accuracy: 0.9953\n",
            "Epoch 123/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9953\n",
            "Epoch 124/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0246 - val_accuracy: 0.9953\n",
            "Epoch 126/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1392 - val_accuracy: 0.9579\n",
            "Epoch 127/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0090 - val_accuracy: 0.9953\n",
            "Epoch 128/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9953\n",
            "Epoch 129/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0158 - val_accuracy: 0.9953\n",
            "Epoch 130/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9907\n",
            "Epoch 131/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0040 - val_accuracy: 0.9953\n",
            "Epoch 133/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.0170 - val_accuracy: 0.9953\n",
            "Epoch 136/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0353 - val_accuracy: 0.9953\n",
            "Epoch 137/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 1.0195 - val_accuracy: 0.8271\n",
            "Epoch 138/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.2648 - val_accuracy: 0.9533\n",
            "Epoch 139/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.0998 - val_accuracy: 0.9813\n",
            "Epoch 140/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0208 - val_accuracy: 0.9953\n",
            "Epoch 141/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0076 - val_accuracy: 0.9953\n",
            "Epoch 142/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0074 - val_accuracy: 0.9953\n",
            "Epoch 143/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0071 - val_accuracy: 0.9953\n",
            "Epoch 144/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0065 - val_accuracy: 0.9953\n",
            "Epoch 145/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.6465e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0075 - val_accuracy: 0.9953\n",
            "Epoch 148/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 3.2803e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 4.3233e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0217 - accuracy: 0.9953 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 3.1525e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9953\n",
            "Epoch 154/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 5.5791e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0235 - val_accuracy: 0.9953\n",
            "Epoch 156/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
            "Epoch 158/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0852 - val_accuracy: 0.9860\n",
            "Epoch 159/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.2743 - val_accuracy: 0.9393\n",
            "Epoch 160/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0068 - accuracy: 0.9969 - val_loss: 6.6622e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
            "Epoch 163/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0444 - val_accuracy: 0.9860\n",
            "Epoch 165/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0136 - val_accuracy: 0.9953\n",
            "Epoch 166/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0161 - val_accuracy: 0.9953\n",
            "Epoch 167/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 1.8878e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 7.0848e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 1.8416e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 3.7220e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 9.9588e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 1.9519e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.3249 - val_accuracy: 0.9346\n",
            "Epoch 175/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.0113 - val_accuracy: 0.9953\n",
            "Epoch 176/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0039 - val_accuracy: 0.9953\n",
            "Epoch 177/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 4.8981e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0067 - val_accuracy: 0.9953\n",
            "Epoch 179/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0060 - val_accuracy: 0.9953\n",
            "Epoch 180/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.8123e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.0061e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 1.1505e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 1.8991e-04 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0491 - val_accuracy: 0.9953\n",
            "Epoch 187/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0495 - val_accuracy: 0.9813\n",
            "Epoch 189/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.0370 - val_accuracy: 0.9860\n",
            "Epoch 190/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0058 - val_accuracy: 0.9953\n",
            "Epoch 191/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0039 - val_accuracy: 0.9953\n",
            "Epoch 194/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 9.9151e-04 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9953\n",
            "Epoch 196/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 9.9797e-04 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 4.8122e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 2.7418e-04 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 4.0346e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KikcQb9ZpuLB"
      },
      "source": [
        "# model.save(dir_path + 'Models/gestures.h5')"
      ],
      "id": "KikcQb9ZpuLB",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "integrated-optimization",
        "outputId": "96fc128c-cb97-46ef-ee1e-8ccca902f59c"
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=24)\n",
        "print(\"test loss, test acc:\", results)\n",
        "model.save(dir_path + 'Models/gestures_bidir', save_format='tf')"
      ],
      "id": "integrated-optimization",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6125 - accuracy: 0.9278\n",
            "test loss, test acc: [0.6125446557998657, 0.927756667137146]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_bidir/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_bidir/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFsQ_tEXw8WX"
      },
      "source": [
        "# new_model = load_model(dir_path + 'Models/gestures.h5')\n",
        "# print(\"Evaluate on test data\")\n",
        "# results = new_model.evaluate(x_test, y_test, batch_size=80)\n",
        "# print(\"test loss, test acc:\", results)"
      ],
      "id": "hFsQ_tEXw8WX",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faWZ2lOQ09Dj",
        "outputId": "fb022058-1eb1-41f4-9131-8f05c4c49333"
      },
      "source": [
        "min_max_scaler.data_min_"
      ],
      "id": "faWZ2lOQ09Dj",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,\n",
              "          0.    ,    0.    ,    0.    ,    0.    , -591.101 ,  -12.7777,\n",
              "       -190.142 , -626.233 ,    0.    , -238.535 , -648.629 ,    0.    ,\n",
              "       -251.495 , -643.156 ,    0.    , -243.005 , -675.481 ,    0.    ,\n",
              "       -220.466 , -607.075 ,    0.    , -158.459 ,    0.    ,    0.    ,\n",
              "          0.    ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLaXSPfzPA8k",
        "outputId": "4c0d9fde-0be1-4253-cfc4-c40bb94f17ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "min_max_scaler.data_max_"
      ],
      "id": "qLaXSPfzPA8k",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([180.   , 180.   , 180.   , 179.999, 179.991, 180.   , 179.983,\n",
              "       180.   , 179.985, 179.985, 539.053, 468.363, 720.07 , 581.654,\n",
              "       522.811, 709.384, 585.01 , 508.522, 705.543, 567.779, 478.013,\n",
              "       702.861, 544.45 , 478.722, 693.173, 499.893, 466.308, 707.228,\n",
              "       127.401, 161.082, 127.977])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOWq0Fev1RI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8e3075-96fe-4de2-cdc9-e41f3bbaf737"
      },
      "source": [
        "model.input"
      ],
      "id": "NOWq0Fev1RI-",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 90, 31) dtype=float64 (created by layer 'bidirectional_input')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIACF0-aQgh"
      },
      "source": [
        ""
      ],
      "id": "FhIACF0-aQgh",
      "execution_count": 17,
      "outputs": []
    }
  ]
}
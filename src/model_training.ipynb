{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feature_computation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "caring-species"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Bidirectional\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
        "# dir_path = './' #local\n",
        "dir_path = './drive/MyDrive/BAKA/' #colab"
      ],
      "id": "caring-species",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KstfPbJfzIAV",
        "outputId": "70ed484d-d8ca-49ac-d607-82d5cf455de9"
      },
      "source": [
        "#uncomment in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', sep=' ', index_col=False )\n",
        "# test = np.genfromtxt(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', delimiter=' ',dtype='float64')\n",
        "df = pd.read_csv(dir_path + 'DataCollection' + '/' + '1' + '/' + '0.txt', header=None, sep=' ')\n",
        "# df.drop(df.index[60:])\n",
        "# filler = np.zeros((100-len(df), 31))\n",
        "# df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "# df\n",
        "if len(df.columns) > 31:\n",
        "  df = df.drop(columns=[31])\n",
        "# df = df.drop(df.index[60:])\n",
        "# df\n",
        "# sp_df = np.array_split(df, 2)\n",
        "# sp_df[0]"
      ],
      "id": "KstfPbJfzIAV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LynMzTXVtjh_"
      },
      "source": [
        "# for i in ['6']:\n",
        "#     samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
        "#     num_tests = int(len(samples)/5);\n",
        "#     shuffle(samples, random_state = 0)\n",
        "#     for k in range(0, len(samples)):\n",
        "# #         df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
        "#         df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "#         df = df.drop(df.index[60:])\n",
        "#         if len(df.columns) > 31:\n",
        "#           df = df.drop(columns=[31])\n",
        "#         if df.isnull().values.any():\n",
        "#           print(i, \" \", samples[k])\n",
        "#         print(samples[k])\n",
        "#         display(df)\n",
        "#         # # if len(df) < 100:\n",
        "#         # #     filler = np.zeros((100-len(df), 31))\n",
        "#         # #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "#         # x_test.append(df.to_numpy())\n",
        "#         # y_test.append(int(i));"
      ],
      "id": "LynMzTXVtjh_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "signal-friendly",
        "outputId": "2fbcb5c4-2a63-4ef9-c316-966c92162fd4"
      },
      "source": [
        "files = os.listdir(dir_path + 'DataCollection')\n",
        "files"
      ],
      "id": "signal-friendly",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4', '7', '8', '0', '5', '2', '3', '6', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "annoying-rotation",
        "outputId": "c7a6949c-99fb-4ddf-8bce-5cdd4578f15c"
      },
      "source": [
        "x_train = [];\n",
        "y_train = [];\n",
        "\n",
        "x_test = [];\n",
        "y_test = [];\n",
        "for i in files:\n",
        "    samples = os.listdir(dir_path + 'DataCollection' + '/' + i)\n",
        "    num_tests = int(len(samples)/5);\n",
        "    shuffle(samples, random_state = 0)\n",
        "    for k in range(0, num_tests):\n",
        "#         df = np.genfromtxt(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], delimiter=' ',dtype='float64')\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        # df = df.drop(df.index[60:])\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_test.append(df.to_numpy())\n",
        "        y_test.append(int(i));\n",
        "    \n",
        "    for k in range(num_tests, len(samples)):\n",
        "        df = pd.read_csv(dir_path + 'DataCollection' + '/' + i + '/' + samples[k], header=None, sep=' ')\n",
        "        # df = df.drop(df.index[60:])\n",
        "        if len(df.columns) > 31:\n",
        "          df = df.drop(columns=[31])\n",
        "        if df.isnull().values.any():\n",
        "          print(i, \" \", samples[k])\n",
        "        # df = df.drop(df.index[100:])\n",
        "        # if len(df) < 100:\n",
        "        #     filler = np.zeros((100-len(df), 31))\n",
        "        #     df = df.append(pd.DataFrame(filler), ignore_index=True )\n",
        "        x_train.append(df.to_numpy())\n",
        "        y_train.append(int(i));\n",
        "    \n",
        "    print(len(samples), ' ', num_tests, ' ', len(samples)- num_tests)\n",
        "# print(len(x_train))\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train);\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n"
      ],
      "id": "annoying-rotation",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "204   40   164\n",
            "264   52   212\n",
            "233   46   187\n",
            "253   50   203\n",
            "254   50   204\n",
            "320   64   256\n",
            "285   57   228\n",
            "266   53   213\n",
            "319   63   256\n",
            "x_train.shape:  (1923, 90, 31)\n",
            "y_train.shiape:  (1923,)\n",
            "x_test.shape:  (475, 90, 31)\n",
            "y_test.shape:  (475,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_7kAXmt41Kf"
      },
      "source": [
        ""
      ],
      "id": "n_7kAXmt41Kf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orange-character",
        "outputId": "5130fb0e-a018-466d-e660-953737ae9fac"
      },
      "source": [
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "\n"
      ],
      "id": "orange-character",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (1923, 90, 31)\n",
            "y_train.shiape:  (1923,)\n",
            "x_test.shape:  (475, 90, 31)\n",
            "y_test.shape:  (475,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-cheat"
      },
      "source": [
        "def scale_data(data, min_max_scaler):\n",
        "    for i in range(len(data)):\n",
        "        data[i] = min_max_scaler.transform(data[i])\n",
        "    return data"
      ],
      "id": "sensitive-cheat",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broke-sailing"
      },
      "source": [
        "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_train.shape\n",
        "x_train = np.reshape(x_train, newshape=(-1, num_features))\n",
        "x_train = min_max_scaler.fit_transform(x_train)\n",
        "x_train = np.reshape(x_train, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "\n",
        "num_instances, num_time_steps, num_features = x_test.shape\n",
        "x_test = np.reshape(x_test, newshape=(-1, num_features))\n",
        "x_test = min_max_scaler.transform(x_test)\n",
        "x_test = np.reshape(x_test, newshape=(num_instances, num_time_steps, num_features))\n",
        "\n",
        "x_test, y_test = shuffle(x_test, y_test, random_state=0)\n"
      ],
      "id": "broke-sailing",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "discrete-kansas",
        "outputId": "2ecd78c1-3e4e-4097-831f-ef069f3e6154"
      },
      "source": [
        "# x_train = np.delete(x_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "# y_train = np.delete(y_train, [0,1,2,3,4,5,6,7,8], 0)\n",
        "print(\"x_train.shape: \", x_train.shape)\n",
        "print(\"y_train.shiape: \", y_train.shape)\n",
        "print(\"x_test.shape: \", x_test.shape)\n",
        "print(\"y_test.shape: \", y_test.shape)\n",
        "# print(y_train)\n",
        "# print(\"\\n\")\n",
        "# print(y_test)\n",
        "\n",
        "# y_train = y_train.astype('int')\n",
        "\n",
        "# print(y_train)\n"
      ],
      "id": "discrete-kansas",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape:  (1923, 90, 31)\n",
            "y_train.shiape:  (1923,)\n",
            "x_test.shape:  (475, 90, 31)\n",
            "y_test.shape:  (475,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhabYU0vjbLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483eb3cc-0cfa-4966-a647-bcb858f46c20"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=90, return_sequences=True ,dtype='float64'),input_shape=x_train.shape[1:],dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Bidirectional(LSTM(units=90 ,dtype='float64') ,dtype='float64'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "# model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "model.add(Dense(len(files), activation='softmax',dtype='float64'))\n",
        "model.summary()"
      ],
      "id": "lhabYU0vjbLQ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 90, 180)           87840     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 90, 180)           720       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 90, 180)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 180)               195120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 180)               720       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9)                 1629      \n",
            "=================================================================\n",
            "Total params: 286,029\n",
            "Trainable params: 285,309\n",
            "Non-trainable params: 720\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-mystery"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(LSTM(units=60, input_shape=x_train.shape[1:], return_sequences=True,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60, return_sequences=True ,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60, return_sequences=True ,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(60,dtype='float64'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "# model.add(Dense(7, activation='softmax',dtype='float64'))\n",
        "# model.summary()"
      ],
      "id": "senior-mystery",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "after-sperm",
        "outputId": "f96417fa-def8-4612-d556-7cb32d378c21"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-5)\n",
        "\n",
        "checkpoint_filepath = dir_path + 'Checkpoints/'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "\n",
        "gestures = model.fit(x = x_train,\n",
        "            y = y_train,\n",
        "            epochs=150,\n",
        "            validation_split=0.1, #split 10% of the trainning set for the validation set,\n",
        "            batch_size=24,\n",
        "            callbacks=[model_checkpoint_callback],\n",
        "            shuffle=True\n",
        "         )"
      ],
      "id": "after-sperm",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - 12s 64ms/step - loss: 2.7640 - accuracy: 0.2514 - val_loss: 2.0470 - val_accuracy: 0.2694\n",
            "Epoch 2/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 1.5562 - accuracy: 0.5035 - val_loss: 1.6698 - val_accuracy: 0.5337\n",
            "Epoch 3/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 1.1547 - accuracy: 0.6098 - val_loss: 1.0918 - val_accuracy: 0.8549\n",
            "Epoch 4/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.8005 - accuracy: 0.7301 - val_loss: 0.6107 - val_accuracy: 0.9482\n",
            "Epoch 5/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.6340 - accuracy: 0.7844 - val_loss: 0.3090 - val_accuracy: 0.9482\n",
            "Epoch 6/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.5469 - accuracy: 0.8127 - val_loss: 0.1531 - val_accuracy: 0.9482\n",
            "Epoch 7/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.4178 - accuracy: 0.8624 - val_loss: 0.1089 - val_accuracy: 0.9585\n",
            "Epoch 8/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.3489 - accuracy: 0.8977 - val_loss: 0.0815 - val_accuracy: 0.9689\n",
            "Epoch 9/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.2876 - accuracy: 0.9017 - val_loss: 0.0487 - val_accuracy: 0.9793\n",
            "Epoch 10/150\n",
            "73/73 [==============================] - 3s 41ms/step - loss: 0.2795 - accuracy: 0.9150 - val_loss: 0.1794 - val_accuracy: 0.9637\n",
            "Epoch 11/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.2483 - accuracy: 0.9168 - val_loss: 0.0427 - val_accuracy: 0.9689\n",
            "Epoch 12/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.2301 - accuracy: 0.9266 - val_loss: 0.0884 - val_accuracy: 0.9741\n",
            "Epoch 13/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.2069 - accuracy: 0.9301 - val_loss: 0.0211 - val_accuracy: 0.9948\n",
            "Epoch 14/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1850 - accuracy: 0.9445 - val_loss: 0.0665 - val_accuracy: 0.9793\n",
            "Epoch 15/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1780 - accuracy: 0.9468 - val_loss: 0.0497 - val_accuracy: 0.9793\n",
            "Epoch 16/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1370 - accuracy: 0.9566 - val_loss: 0.0701 - val_accuracy: 0.9793\n",
            "Epoch 17/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1604 - accuracy: 0.9480 - val_loss: 0.0911 - val_accuracy: 0.9741\n",
            "Epoch 18/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1597 - accuracy: 0.9462 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
            "Epoch 19/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1305 - accuracy: 0.9618 - val_loss: 0.0712 - val_accuracy: 0.9793\n",
            "Epoch 20/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1253 - accuracy: 0.9659 - val_loss: 0.1081 - val_accuracy: 0.9741\n",
            "Epoch 21/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1285 - accuracy: 0.9630 - val_loss: 0.0389 - val_accuracy: 0.9845\n",
            "Epoch 22/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1028 - accuracy: 0.9671 - val_loss: 0.0400 - val_accuracy: 0.9793\n",
            "Epoch 23/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1013 - accuracy: 0.9723 - val_loss: 0.0204 - val_accuracy: 0.9896\n",
            "Epoch 24/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1085 - accuracy: 0.9665 - val_loss: 0.0349 - val_accuracy: 0.9793\n",
            "Epoch 25/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1033 - accuracy: 0.9671 - val_loss: 0.0185 - val_accuracy: 0.9948\n",
            "Epoch 26/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0966 - accuracy: 0.9740 - val_loss: 0.0200 - val_accuracy: 0.9948\n",
            "Epoch 27/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1166 - accuracy: 0.9659 - val_loss: 0.0260 - val_accuracy: 0.9896\n",
            "Epoch 28/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1104 - accuracy: 0.9676 - val_loss: 0.0168 - val_accuracy: 0.9845\n",
            "Epoch 29/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0962 - accuracy: 0.9717 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
            "Epoch 30/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1057 - accuracy: 0.9636 - val_loss: 0.0516 - val_accuracy: 0.9845\n",
            "Epoch 31/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1041 - accuracy: 0.9711 - val_loss: 0.0869 - val_accuracy: 0.9741\n",
            "Epoch 32/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0880 - accuracy: 0.9740 - val_loss: 0.1071 - val_accuracy: 0.9741\n",
            "Epoch 33/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0927 - accuracy: 0.9723 - val_loss: 0.1880 - val_accuracy: 0.9741\n",
            "Epoch 34/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0910 - accuracy: 0.9740 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0879 - accuracy: 0.9740 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0830 - accuracy: 0.9746 - val_loss: 0.0194 - val_accuracy: 0.9948\n",
            "Epoch 37/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0603 - accuracy: 0.9803 - val_loss: 0.0202 - val_accuracy: 0.9896\n",
            "Epoch 38/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 0.0349 - val_accuracy: 0.9845\n",
            "Epoch 39/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0605 - accuracy: 0.9821 - val_loss: 0.0169 - val_accuracy: 0.9948\n",
            "Epoch 40/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0820 - accuracy: 0.9711 - val_loss: 0.0203 - val_accuracy: 0.9896\n",
            "Epoch 41/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0876 - accuracy: 0.9728 - val_loss: 0.0236 - val_accuracy: 0.9896\n",
            "Epoch 42/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1434 - accuracy: 0.9549 - val_loss: 0.0294 - val_accuracy: 0.9845\n",
            "Epoch 43/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.1025 - accuracy: 0.9694 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0771 - accuracy: 0.9792 - val_loss: 0.1451 - val_accuracy: 0.9793\n",
            "Epoch 45/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0821 - accuracy: 0.9751 - val_loss: 0.0096 - val_accuracy: 0.9948\n",
            "Epoch 46/150\n",
            "73/73 [==============================] - 3s 41ms/step - loss: 0.0664 - accuracy: 0.9809 - val_loss: 0.1633 - val_accuracy: 0.9689\n",
            "Epoch 47/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0772 - accuracy: 0.9688 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0812 - accuracy: 0.9798 - val_loss: 0.0088 - val_accuracy: 0.9948\n",
            "Epoch 49/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0605 - accuracy: 0.9821 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
            "Epoch 52/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0683 - accuracy: 0.9809 - val_loss: 0.0363 - val_accuracy: 0.9845\n",
            "Epoch 53/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
            "Epoch 54/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0681 - accuracy: 0.9786 - val_loss: 0.0516 - val_accuracy: 0.9793\n",
            "Epoch 55/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.0927 - val_accuracy: 0.9793\n",
            "Epoch 56/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0631 - accuracy: 0.9879 - val_loss: 0.0921 - val_accuracy: 0.9845\n",
            "Epoch 57/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0834 - accuracy: 0.9751 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
            "Epoch 58/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0859 - accuracy: 0.9734 - val_loss: 0.0983 - val_accuracy: 0.9689\n",
            "Epoch 59/150\n",
            "73/73 [==============================] - 3s 41ms/step - loss: 0.0738 - accuracy: 0.9798 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
            "Epoch 62/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0452 - accuracy: 0.9873 - val_loss: 0.0255 - val_accuracy: 0.9845\n",
            "Epoch 63/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.0858 - val_accuracy: 0.9793\n",
            "Epoch 64/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
            "Epoch 65/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0521 - accuracy: 0.9873 - val_loss: 0.0269 - val_accuracy: 0.9896\n",
            "Epoch 66/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 0.0075 - val_accuracy: 0.9948\n",
            "Epoch 67/150\n",
            "73/73 [==============================] - 3s 41ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
            "Epoch 68/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0467 - accuracy: 0.9867 - val_loss: 0.0333 - val_accuracy: 0.9845\n",
            "Epoch 69/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.0132 - val_accuracy: 0.9896\n",
            "Epoch 70/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 0.0495 - val_accuracy: 0.9793\n",
            "Epoch 71/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0405 - accuracy: 0.9867 - val_loss: 0.0141 - val_accuracy: 0.9896\n",
            "Epoch 72/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0479 - accuracy: 0.9838 - val_loss: 0.0108 - val_accuracy: 0.9948\n",
            "Epoch 73/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0504 - accuracy: 0.9867 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
            "Epoch 74/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0070 - val_accuracy: 0.9948\n",
            "Epoch 75/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0410 - accuracy: 0.9902 - val_loss: 0.0433 - val_accuracy: 0.9845\n",
            "Epoch 78/150\n",
            "73/73 [==============================] - 3s 41ms/step - loss: 0.0514 - accuracy: 0.9850 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.1038 - val_accuracy: 0.9793\n",
            "Epoch 82/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0538 - accuracy: 0.9855 - val_loss: 0.1503 - val_accuracy: 0.9741\n",
            "Epoch 83/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 0.1212 - val_accuracy: 0.9689\n",
            "Epoch 84/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0509 - accuracy: 0.9873 - val_loss: 0.0091 - val_accuracy: 0.9948\n",
            "Epoch 85/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0161 - val_accuracy: 0.9948\n",
            "Epoch 86/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0857 - val_accuracy: 0.9793\n",
            "Epoch 87/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0938 - val_accuracy: 0.9637\n",
            "Epoch 88/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0450 - val_accuracy: 0.9845\n",
            "Epoch 89/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0308 - accuracy: 0.9925 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 0.0436 - val_accuracy: 0.9896\n",
            "Epoch 93/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.1089 - val_accuracy: 0.9845\n",
            "Epoch 97/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
            "Epoch 100/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.0257 - val_accuracy: 0.9793\n",
            "Epoch 101/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.0070 - val_accuracy: 0.9948\n",
            "Epoch 102/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.1144 - val_accuracy: 0.9845\n",
            "Epoch 106/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0058 - val_accuracy: 0.9948\n",
            "Epoch 107/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0370 - accuracy: 0.9896 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0501 - accuracy: 0.9855 - val_loss: 0.0261 - val_accuracy: 0.9845\n",
            "Epoch 109/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0628 - val_accuracy: 0.9793\n",
            "Epoch 110/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.2299 - val_accuracy: 0.9741\n",
            "Epoch 111/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
            "Epoch 112/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
            "Epoch 113/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.0098 - val_accuracy: 0.9948\n",
            "Epoch 114/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.0154 - val_accuracy: 0.9896\n",
            "Epoch 115/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0073 - val_accuracy: 0.9948\n",
            "Epoch 116/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0090 - val_accuracy: 0.9948\n",
            "Epoch 117/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0306 - accuracy: 0.9919 - val_loss: 0.0197 - val_accuracy: 0.9845\n",
            "Epoch 118/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0105 - val_accuracy: 0.9948\n",
            "Epoch 119/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0110 - val_accuracy: 0.9948\n",
            "Epoch 120/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.2171 - val_accuracy: 0.9585\n",
            "Epoch 126/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0169 - val_accuracy: 0.9896\n",
            "Epoch 127/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0107 - val_accuracy: 0.9948\n",
            "Epoch 128/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
            "Epoch 129/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.0164 - val_accuracy: 0.9896\n",
            "Epoch 130/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0320 - accuracy: 0.9925 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
            "Epoch 131/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0816 - val_accuracy: 0.9793\n",
            "Epoch 132/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 0.1386 - val_accuracy: 0.9741\n",
            "Epoch 133/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.1639 - val_accuracy: 0.9689\n",
            "Epoch 134/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.5242 - val_accuracy: 0.9275\n",
            "Epoch 135/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0249 - val_accuracy: 0.9845\n",
            "Epoch 136/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0190 - accuracy: 0.9925 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
            "Epoch 137/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
            "Epoch 138/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0216 - val_accuracy: 0.9948\n",
            "Epoch 139/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.0201 - val_accuracy: 0.9948\n",
            "Epoch 140/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
            "Epoch 141/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.1966 - val_accuracy: 0.9741\n",
            "Epoch 142/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.2584 - val_accuracy: 0.9689\n",
            "Epoch 143/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.0237 - val_accuracy: 0.9896\n",
            "Epoch 144/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
            "Epoch 145/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0520 - val_accuracy: 0.9793\n",
            "Epoch 146/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.0177 - val_accuracy: 0.9948\n",
            "Epoch 147/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 0.0189 - val_accuracy: 0.9948\n",
            "Epoch 148/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.0203 - val_accuracy: 0.9948\n",
            "Epoch 149/150\n",
            "73/73 [==============================] - 3s 42ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.0769 - val_accuracy: 0.9793\n",
            "Epoch 150/150\n",
            "73/73 [==============================] - 3s 43ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0424 - val_accuracy: 0.9845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KikcQb9ZpuLB"
      },
      "source": [
        "# model.save(dir_path + 'Models/gestures.h5')"
      ],
      "id": "KikcQb9ZpuLB",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "integrated-optimization",
        "outputId": "8c418b70-148d-45b6-90e0-aae9234a7c29"
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=24)\n",
        "print(\"test loss, test acc:\", results)\n",
        "model.save(dir_path + 'Models/gestures_bidir', save_format='tf')"
      ],
      "id": "integrated-optimization",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4872 - accuracy: 0.9095\n",
            "test loss, test acc: [0.48720380663871765, 0.9094736576080322]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_bidir/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/BAKA/Models/gestures_bidir/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFsQ_tEXw8WX"
      },
      "source": [
        "# new_model = load_model(dir_path + 'Models/gestures.h5')\n",
        "# print(\"Evaluate on test data\")\n",
        "# results = new_model.evaluate(x_test, y_test, batch_size=80)\n",
        "# print(\"test loss, test acc:\", results)"
      ],
      "id": "hFsQ_tEXw8WX",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faWZ2lOQ09Dj",
        "outputId": "df8a398f-b89a-4e01-ac68-8a8f25750317"
      },
      "source": [
        "min_max_scaler.data_min_"
      ],
      "id": "faWZ2lOQ09Dj",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,\n",
              "          0.    ,    0.    ,    0.    ,    0.    , -591.101 ,  -12.7777,\n",
              "       -190.142 , -626.233 ,    0.    , -238.535 , -648.629 ,    0.    ,\n",
              "       -251.495 , -643.156 ,    0.    , -243.005 , -675.481 ,    0.    ,\n",
              "       -220.466 , -607.075 ,    0.    , -158.459 ,    0.    ,    0.    ,\n",
              "          0.    ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLaXSPfzPA8k",
        "outputId": "7f0fab8c-1c64-4df6-e6d2-0988ddf16024"
      },
      "source": [
        "min_max_scaler.data_max_"
      ],
      "id": "qLaXSPfzPA8k",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([180.   , 180.   , 180.   , 179.999, 179.991, 180.   , 179.983,\n",
              "       180.   , 179.985, 179.985, 539.053, 468.363, 720.07 , 581.654,\n",
              "       522.811, 709.384, 585.01 , 508.522, 705.543, 567.779, 478.013,\n",
              "       702.861, 544.45 , 478.722, 693.173, 499.893, 466.308, 707.228,\n",
              "       127.401, 161.082, 127.977])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOWq0Fev1RI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a02fcaf-79e1-424e-a091-483bf0f45a91"
      },
      "source": [
        "model.input"
      ],
      "id": "NOWq0Fev1RI-",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 90, 31) dtype=float64 (created by layer 'bidirectional_input')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIACF0-aQgh"
      },
      "source": [
        ""
      ],
      "id": "FhIACF0-aQgh",
      "execution_count": 18,
      "outputs": []
    }
  ]
}
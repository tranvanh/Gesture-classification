
Feed-forward network (FNN) has its data or input travel in one direction, oriented from the input layer to the output layer, without cycles. [https://analyticsindiamag.com/6-types-of-artificial-neural-networks-currently-being-used-in-todays-technology/]. FNN may or may not contain several hidden layers of various widths. By having no back-loops, FNN generally minimizes error in its prediction by using the backpropagation algorithm to update its weight values. [https://medium.com/towards-artificial-intelligence/main-types-of-neural-networks-and-its-applications-tutorial-734480d7ec8e]\newline

GRAPH\\

The input layer takes input data, vector x, producing y at the output layer. The process of training weights consists of minimizing the loss function L(y,y), y being the target output of input x [12 M].

\subsubsection{Backpropagation}
\input{chapters/neural_network/types_of_nn/backpropagation.tex}
%=======================================================================================================================
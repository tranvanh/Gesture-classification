Backpropagation, short of backward propagation of errors, is a widely used algorithm in training FFN using gradient descent to update the weights. \cite{birlliantbackprop}

MATH

Its generalization is used for other ANNs. Providing a way to compute the gradient of the cost function,
 real number value expressing prediction incorrectness.\cite{Goodfellow-et-al-2016}

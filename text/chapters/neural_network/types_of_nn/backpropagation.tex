Backpropagation, short of backward propagation of errors, is a widely used algorithm in training FFN using gradient descent to update the weights. [https://brilliant.org/wiki/backpropagation/]\newline

MATH \\

Its generalization is used for other ANNs. Providing a way to compute the gradient of the cost function, real number value expressing prediction incorrectness.
[Goodfellow, Bengio \& Courville 2016, p. 200].

Mouse and keyboard are considered to be default devices for human-computer interaction nowadays. But with the maturity in technology, namely virtual and extended reality, the computer's need to understand human's body language is more and more present. Actions such as rotation or grabbing and moving an object in three-dimensional space with a computer mouse are unintuitive. They require a little understanding of the controls to execute the task. The movement is limited to the two-dimensional space of the mouse. Oppose to performing the desired action by hands in our three-dimensional space as we would in real life.

One of the proposed solutions for the issue is gesture recognition, where a general idea is for computers to have the ability to recognize gestures and perform actions base on them. Therefore, several devices were developed to process an image and yield useful data for gesture recognition. Some of them being Microsoft Kinect, a device where the main intention was to interpret whole-body movement, making it lacking in required accuracy for hand gesture recognition. 

Another option would be using a Leap Motion Controller, developed specifically to track hand movements and extract its features, such as positions of fingers, hand rotation, and others. Its accuracy in finger detection is up to 0.01 mm.

Unfortunately, Leap Motion Controller has no official library for gesture recognition, limiting developers from utilizing the controller for its key feature. Orion used to have a gesture detector with its 3.0 version, but the detector is absent with the release of more accurate version 4.0.
Mouse and keyboard are considered to be default provider for human-computer interaction nowadays. But with the maturity in technology, namely virtual and extended reality, the need for computers to understand body language of a human is more and more present. Actions such as rotation or grabbing and moving an object in three-dimensional space, are unnatural if we were to use computer mouse, where its movement is limited to two-dimensional space. Oppose to performing the desired action by hands in our three-dimensional environment.

One of the proposed solutions for the issue is gesture recognition. Where a general idea is for computers to have the ability of recognizing gestures and performing actions base on them. Therefore, several devices were developed to process an image and yield useful data for gesture recognition. Some of them being Microsoft Kinect, a device where the main intention was to interpret whole body movement. Making it lacking in required accurracy for a hand gesture recognition. 

Other option would be using Leap Motion Controller. Developed specificly for tracking hand movements and extracting its features, such as positions of fingers, hand rotation and others. Its accurracy in finger detection is up to 0.01 mm.

Unfortunatly Leap Motion Controller has no official library for gesture recognition. Limiting developers utilizing the controller for its key features.